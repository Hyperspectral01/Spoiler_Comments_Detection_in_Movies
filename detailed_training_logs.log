nohup: ignoring input

==================================================
EPOCH 1/20
==================================================
Training on dataloader 1/38
  Batch 0: Loss = 2.1840, Accuracy = 12.50%
  Batch 5: Loss = 1.1299, Accuracy = 50.00%
  Batch 10: Loss = 1.2313, Accuracy = 53.41%
Training on dataloader 2/38
  Batch 0: Loss = 1.0324, Accuracy = 53.92%
  Batch 5: Loss = 1.2018, Accuracy = 57.75%
  Batch 10: Loss = 1.7845, Accuracy = 59.34%
Training on dataloader 3/38
  Batch 0: Loss = 1.1117, Accuracy = 59.07%
  Batch 5: Loss = 0.5900, Accuracy = 59.66%
  Batch 10: Loss = 0.9392, Accuracy = 60.44%
Training on dataloader 4/38
  Batch 0: Loss = 0.9668, Accuracy = 60.55%
  Batch 5: Loss = 1.1309, Accuracy = 60.79%
  Batch 10: Loss = 1.0830, Accuracy = 59.62%
Training on dataloader 5/38
  Batch 0: Loss = 1.1879, Accuracy = 58.96%
  Batch 5: Loss = 0.8089, Accuracy = 58.12%
  Batch 10: Loss = 1.1732, Accuracy = 57.42%
Training on dataloader 6/38
  Batch 0: Loss = 1.1283, Accuracy = 56.94%
  Batch 5: Loss = 0.9382, Accuracy = 56.79%
  Batch 10: Loss = 0.4326, Accuracy = 57.55%
Training on dataloader 7/38
  Batch 0: Loss = 0.9723, Accuracy = 57.69%
  Batch 5: Loss = 1.3019, Accuracy = 57.84%
  Batch 10: Loss = 0.7071, Accuracy = 58.12%
Training on dataloader 8/38
  Batch 0: Loss = 0.9531, Accuracy = 58.48%
  Batch 5: Loss = 1.4734, Accuracy = 58.85%
  Batch 10: Loss = 0.9567, Accuracy = 59.18%
Training on dataloader 9/38
  Batch 0: Loss = 0.6705, Accuracy = 59.24%
  Batch 5: Loss = 0.9789, Accuracy = 59.90%
  Batch 10: Loss = 0.8078, Accuracy = 60.14%
Training on dataloader 10/38
  Batch 0: Loss = 0.9689, Accuracy = 60.30%
  Batch 5: Loss = 1.2772, Accuracy = 60.29%
  Batch 10: Loss = 0.9177, Accuracy = 60.38%
Training on dataloader 11/38
  Batch 0: Loss = 0.6624, Accuracy = 60.52%
  Batch 5: Loss = 0.8677, Accuracy = 60.70%
  Batch 10: Loss = 1.2308, Accuracy = 60.67%
Training on dataloader 12/38
  Batch 0: Loss = 0.3959, Accuracy = 60.89%
  Batch 5: Loss = 0.4993, Accuracy = 61.31%
  Batch 10: Loss = 0.6415, Accuracy = 61.97%
Training on dataloader 13/38
  Batch 0: Loss = 1.4625, Accuracy = 62.00%
  Batch 5: Loss = 0.3772, Accuracy = 62.61%
  Batch 10: Loss = 0.4587, Accuracy = 62.68%
Training on dataloader 14/38
  Batch 0: Loss = 0.4095, Accuracy = 63.02%
  Batch 5: Loss = 0.5897, Accuracy = 63.71%
  Batch 10: Loss = 0.2914, Accuracy = 64.35%
Training on dataloader 15/38
  Batch 0: Loss = 1.1584, Accuracy = 64.25%
  Batch 5: Loss = 0.6526, Accuracy = 64.35%
  Batch 10: Loss = 1.3378, Accuracy = 64.37%
  Batch 15: Loss = 0.4051, Accuracy = 64.66%
  Batch 20: Loss = 0.2659, Accuracy = 65.07%
  Batch 25: Loss = 0.3605, Accuracy = 65.78%
  Batch 30: Loss = 0.1116, Accuracy = 66.31%
Training on dataloader 16/38
  Batch 0: Loss = 1.9731, Accuracy = 66.41%
  Batch 5: Loss = 1.9899, Accuracy = 66.50%
  Batch 10: Loss = 1.2598, Accuracy = 66.29%
Training on dataloader 17/38
  Batch 0: Loss = 0.5045, Accuracy = 66.35%
  Batch 5: Loss = 0.3894, Accuracy = 66.84%
  Batch 10: Loss = 0.1674, Accuracy = 67.37%
  Batch 15: Loss = 0.3411, Accuracy = 67.81%
  Batch 20: Loss = 0.2278, Accuracy = 68.30%
Training on dataloader 18/38
  Batch 0: Loss = 0.4254, Accuracy = 68.65%
  Batch 5: Loss = 0.2339, Accuracy = 68.84%
  Batch 10: Loss = 0.8846, Accuracy = 69.01%
Training on dataloader 19/38
  Batch 0: Loss = 1.0239, Accuracy = 68.93%
  Batch 5: Loss = 0.2329, Accuracy = 69.10%
  Batch 10: Loss = 1.0359, Accuracy = 69.12%
Training on dataloader 20/38
  Batch 0: Loss = 0.5974, Accuracy = 69.10%
  Batch 5: Loss = 0.3568, Accuracy = 69.21%
  Batch 10: Loss = 0.3602, Accuracy = 69.27%
Training on dataloader 21/38
  Batch 0: Loss = 0.3241, Accuracy = 69.34%
  Batch 5: Loss = 0.8241, Accuracy = 69.54%
  Batch 10: Loss = 0.6578, Accuracy = 69.72%
  Batch 15: Loss = 0.5160, Accuracy = 69.86%
  Batch 20: Loss = 0.6931, Accuracy = 70.03%
Training on dataloader 22/38
  Batch 0: Loss = 0.5631, Accuracy = 70.32%
  Batch 5: Loss = 0.4356, Accuracy = 70.65%
  Batch 10: Loss = 0.1874, Accuracy = 70.89%
Training on dataloader 23/38
  Batch 0: Loss = 0.9555, Accuracy = 70.96%
  Batch 5: Loss = 0.6199, Accuracy = 71.22%
  Batch 10: Loss = 0.9448, Accuracy = 71.20%
Training on dataloader 24/38
  Batch 0: Loss = 0.5888, Accuracy = 71.31%
  Batch 5: Loss = 1.0650, Accuracy = 71.25%
  Batch 10: Loss = 0.9536, Accuracy = 71.00%
Training on dataloader 25/38
  Batch 0: Loss = 1.0562, Accuracy = 70.97%
  Batch 5: Loss = 0.5720, Accuracy = 70.99%
  Batch 10: Loss = 0.4472, Accuracy = 70.87%
Training on dataloader 26/38
  Batch 0: Loss = 0.5183, Accuracy = 70.87%
  Batch 5: Loss = 0.3300, Accuracy = 71.04%
  Batch 10: Loss = 0.4017, Accuracy = 71.20%
Training on dataloader 27/38
  Batch 0: Loss = 0.4522, Accuracy = 71.31%
  Batch 5: Loss = 0.3912, Accuracy = 71.60%
  Batch 10: Loss = 0.3238, Accuracy = 71.82%
  Batch 15: Loss = 0.2059, Accuracy = 72.10%
  Batch 20: Loss = 0.7541, Accuracy = 72.34%
Training on dataloader 28/38
  Batch 0: Loss = 1.0850, Accuracy = 72.41%
  Batch 5: Loss = 2.2983, Accuracy = 72.45%
  Batch 10: Loss = 0.4772, Accuracy = 72.61%
Training on dataloader 29/38
  Batch 0: Loss = 0.8028, Accuracy = 72.67%
  Batch 5: Loss = 0.3223, Accuracy = 72.73%
  Batch 10: Loss = 1.7563, Accuracy = 72.64%
Training on dataloader 30/38
  Batch 0: Loss = 0.6022, Accuracy = 72.55%
  Batch 5: Loss = 0.5105, Accuracy = 72.52%
  Batch 10: Loss = 1.0032, Accuracy = 72.34%
Error in batch 12 of dataloader 29: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 31/38
  Batch 0: Loss = 0.4087, Accuracy = 72.38%
  Batch 5: Loss = 0.3043, Accuracy = 72.56%
  Batch 10: Loss = 0.7262, Accuracy = 72.68%
  Batch 15: Loss = 0.2343, Accuracy = 72.74%
  Batch 20: Loss = 0.3145, Accuracy = 72.97%
Training on dataloader 32/38
  Batch 0: Loss = 0.7028, Accuracy = 73.09%
  Batch 5: Loss = 0.2360, Accuracy = 73.34%
  Batch 10: Loss = 0.1188, Accuracy = 73.52%
  Batch 15: Loss = 0.1065, Accuracy = 73.73%
  Batch 20: Loss = 0.1193, Accuracy = 74.00%
Training on dataloader 33/38
  Batch 0: Loss = 0.0973, Accuracy = 74.16%
  Batch 5: Loss = 0.1058, Accuracy = 74.41%
  Batch 10: Loss = 0.1223, Accuracy = 74.58%
  Batch 15: Loss = 0.3149, Accuracy = 74.74%
  Batch 20: Loss = 0.1118, Accuracy = 75.01%
Error in batch 22 of dataloader 32: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 34/38
  Batch 0: Loss = 0.1502, Accuracy = 75.08%
  Batch 5: Loss = 0.2439, Accuracy = 75.06%
  Batch 10: Loss = 0.8188, Accuracy = 75.06%
Training on dataloader 35/38
  Batch 0: Loss = 1.6637, Accuracy = 75.02%
  Batch 5: Loss = 0.1665, Accuracy = 75.09%
  Batch 10: Loss = 0.3206, Accuracy = 75.07%
Training on dataloader 36/38
  Batch 0: Loss = 0.1624, Accuracy = 75.15%
  Batch 5: Loss = 0.1478, Accuracy = 75.32%
  Batch 10: Loss = 0.2312, Accuracy = 75.51%
  Batch 15: Loss = 0.1617, Accuracy = 75.72%
  Batch 20: Loss = 0.1647, Accuracy = 75.96%
Training on dataloader 37/38
  Batch 0: Loss = 1.9621, Accuracy = 76.11%
  Batch 5: Loss = 0.0886, Accuracy = 76.34%
  Batch 10: Loss = 0.1017, Accuracy = 76.53%
  Batch 15: Loss = 0.2200, Accuracy = 76.71%
  Batch 20: Loss = 0.5334, Accuracy = 76.85%
Training on dataloader 38/38
  Batch 0: Loss = 0.7358, Accuracy = 76.89%
  Batch 5: Loss = 0.3010, Accuracy = 76.94%
  Batch 10: Loss = 0.1827, Accuracy = 77.03%

=== TRAINING EPOCH SUMMARY ===
Average Loss: 0.6836
Accuracy: 77.01%
Total Samples: 4488
==============================
Evaluating on dataloader 1/3
  Batch 0: Loss = 0.5829, Accuracy = 75.00%
  Batch 5: Loss = 0.3093, Accuracy = 68.75%
  Batch 10: Loss = 0.3668, Accuracy = 76.14%
  Batch 15: Loss = 0.1936, Accuracy = 77.34%
  Batch 20: Loss = 0.0285, Accuracy = 79.76%
Evaluating on dataloader 2/3
  Batch 0: Loss = 0.8121, Accuracy = 80.95%
  Batch 5: Loss = 0.6983, Accuracy = 79.48%
  Batch 10: Loss = 0.1943, Accuracy = 79.18%
  Batch 15: Loss = 0.6911, Accuracy = 79.61%
  Batch 20: Loss = 0.6087, Accuracy = 79.66%
  Batch 25: Loss = 0.0296, Accuracy = 80.31%
Evaluating on dataloader 3/3
  Batch 0: Loss = 1.1713, Accuracy = 79.95%
  Batch 5: Loss = 0.5432, Accuracy = 79.49%
  Batch 10: Loss = 0.6260, Accuracy = 78.90%

=== VALIDATION EPOCH SUMMARY ===
Average Loss: 0.4580
Accuracy: 78.72%
Total Samples: 484
===================================
New best validation accuracy: 78.72% - Models saved!

==================================================
EPOCH 2/20
==================================================
Training on dataloader 1/38
  Batch 0: Loss = 0.9204, Accuracy = 62.50%
  Batch 5: Loss = 0.3548, Accuracy = 64.58%
  Batch 10: Loss = 1.3494, Accuracy = 69.32%
Training on dataloader 2/38
  Batch 0: Loss = 0.3776, Accuracy = 72.55%
  Batch 5: Loss = 0.7421, Accuracy = 69.72%
  Batch 10: Loss = 0.6923, Accuracy = 73.08%
Training on dataloader 3/38
  Batch 0: Loss = 0.9195, Accuracy = 72.02%
  Batch 5: Loss = 0.2412, Accuracy = 75.11%
  Batch 10: Loss = 0.6691, Accuracy = 74.73%
Training on dataloader 4/38
  Batch 0: Loss = 0.3641, Accuracy = 75.09%
  Batch 5: Loss = 0.7260, Accuracy = 75.99%
  Batch 10: Loss = 0.5274, Accuracy = 75.88%
Training on dataloader 5/38
  Batch 0: Loss = 1.2631, Accuracy = 76.10%
  Batch 5: Loss = 0.5303, Accuracy = 75.76%
  Batch 10: Loss = 1.5827, Accuracy = 74.84%
Training on dataloader 6/38
  Batch 0: Loss = 0.5637, Accuracy = 74.33%
  Batch 5: Loss = 0.4312, Accuracy = 73.80%
  Batch 10: Loss = 0.3805, Accuracy = 74.42%
Training on dataloader 7/38
  Batch 0: Loss = 0.7267, Accuracy = 74.44%
  Batch 5: Loss = 1.1944, Accuracy = 74.80%
  Batch 10: Loss = 1.0569, Accuracy = 74.51%
Training on dataloader 8/38
  Batch 0: Loss = 0.3944, Accuracy = 74.70%
  Batch 5: Loss = 0.2942, Accuracy = 75.14%
  Batch 10: Loss = 0.2092, Accuracy = 75.93%
Training on dataloader 9/38
  Batch 0: Loss = 0.4639, Accuracy = 76.04%
  Batch 5: Loss = 0.3779, Accuracy = 76.49%
  Batch 10: Loss = 0.4074, Accuracy = 76.18%
Training on dataloader 10/38
  Batch 0: Loss = 0.2223, Accuracy = 76.39%
  Batch 5: Loss = 0.3249, Accuracy = 76.44%
  Batch 10: Loss = 0.4485, Accuracy = 76.59%
Training on dataloader 11/38
  Batch 0: Loss = 0.8761, Accuracy = 76.46%
  Batch 5: Loss = 0.9478, Accuracy = 75.80%
  Batch 10: Loss = 0.4828, Accuracy = 75.77%
Training on dataloader 12/38
  Batch 0: Loss = 0.5225, Accuracy = 75.57%
  Batch 5: Loss = 0.3864, Accuracy = 75.91%
  Batch 10: Loss = 0.2439, Accuracy = 76.32%
Training on dataloader 13/38
  Batch 0: Loss = 0.8654, Accuracy = 76.26%
  Batch 5: Loss = 0.6211, Accuracy = 76.13%
  Batch 10: Loss = 0.8393, Accuracy = 76.34%
Training on dataloader 14/38
  Batch 0: Loss = 0.2950, Accuracy = 76.61%
  Batch 5: Loss = 0.8895, Accuracy = 76.40%
  Batch 10: Loss = 0.1483, Accuracy = 76.66%
Training on dataloader 15/38
  Batch 0: Loss = 1.1627, Accuracy = 76.64%
  Batch 5: Loss = 0.1857, Accuracy = 76.88%
  Batch 10: Loss = 0.3667, Accuracy = 77.18%
  Batch 15: Loss = 0.2288, Accuracy = 77.47%
  Batch 20: Loss = 0.8321, Accuracy = 77.60%
  Batch 25: Loss = 0.2636, Accuracy = 77.99%
  Batch 30: Loss = 0.2067, Accuracy = 78.30%
Training on dataloader 16/38
  Batch 0: Loss = 1.4377, Accuracy = 78.16%
  Batch 5: Loss = 1.3179, Accuracy = 77.83%
  Batch 10: Loss = 1.4273, Accuracy = 77.64%
Training on dataloader 17/38
  Batch 0: Loss = 0.5497, Accuracy = 77.59%
  Batch 5: Loss = 0.1932, Accuracy = 77.93%
  Batch 10: Loss = 0.2513, Accuracy = 78.43%
  Batch 15: Loss = 0.5511, Accuracy = 78.80%
  Batch 20: Loss = 0.2277, Accuracy = 79.04%
Training on dataloader 18/38
  Batch 0: Loss = 0.4712, Accuracy = 79.26%
  Batch 5: Loss = 0.3080, Accuracy = 79.33%
  Batch 10: Loss = 0.1250, Accuracy = 79.45%
Training on dataloader 19/38
  Batch 0: Loss = 0.1401, Accuracy = 79.59%
  Batch 5: Loss = 0.5330, Accuracy = 79.55%
  Batch 10: Loss = 0.1194, Accuracy = 79.75%
Training on dataloader 20/38
  Batch 0: Loss = 0.4556, Accuracy = 79.83%
  Batch 5: Loss = 1.0433, Accuracy = 79.93%
  Batch 10: Loss = 1.0322, Accuracy = 79.89%
Training on dataloader 21/38
  Batch 0: Loss = 0.1470, Accuracy = 80.01%
  Batch 5: Loss = 0.1151, Accuracy = 80.33%
  Batch 10: Loss = 0.3447, Accuracy = 80.50%
  Batch 15: Loss = 0.3099, Accuracy = 80.40%
  Batch 20: Loss = 0.2180, Accuracy = 80.48%
Training on dataloader 22/38
  Batch 0: Loss = 0.2498, Accuracy = 80.61%
  Batch 5: Loss = 0.1913, Accuracy = 80.81%
  Batch 10: Loss = 0.3267, Accuracy = 81.04%
Training on dataloader 23/38
  Batch 0: Loss = 0.4636, Accuracy = 81.00%
  Batch 5: Loss = 0.4413, Accuracy = 81.03%
  Batch 10: Loss = 0.6436, Accuracy = 80.97%
Training on dataloader 24/38
  Batch 0: Loss = 0.3338, Accuracy = 81.05%
  Batch 5: Loss = 0.4312, Accuracy = 80.77%
  Batch 10: Loss = 0.7066, Accuracy = 80.53%
Training on dataloader 25/38
  Batch 0: Loss = 0.4613, Accuracy = 80.53%
  Batch 5: Loss = 0.3783, Accuracy = 80.56%
  Batch 10: Loss = 0.2444, Accuracy = 80.66%
Training on dataloader 26/38
  Batch 0: Loss = 0.2925, Accuracy = 80.73%
  Batch 5: Loss = 0.3264, Accuracy = 80.93%
  Batch 10: Loss = 0.1449, Accuracy = 81.13%
Training on dataloader 27/38
  Batch 0: Loss = 0.2325, Accuracy = 81.19%
  Batch 5: Loss = 0.4642, Accuracy = 81.35%
  Batch 10: Loss = 0.0931, Accuracy = 81.50%
  Batch 15: Loss = 0.0945, Accuracy = 81.65%
  Batch 20: Loss = 0.2410, Accuracy = 81.80%
Training on dataloader 28/38
  Batch 0: Loss = 0.1094, Accuracy = 81.89%
  Batch 5: Loss = 0.7626, Accuracy = 81.90%
  Batch 10: Loss = 0.2877, Accuracy = 82.00%
Training on dataloader 29/38
  Batch 0: Loss = 1.2766, Accuracy = 82.02%
  Batch 5: Loss = 0.3282, Accuracy = 81.93%
  Batch 10: Loss = 0.2466, Accuracy = 81.87%
Training on dataloader 30/38
  Batch 0: Loss = 0.2945, Accuracy = 81.81%
  Batch 5: Loss = 0.8061, Accuracy = 81.75%
  Batch 10: Loss = 0.7964, Accuracy = 81.79%
Error in batch 12 of dataloader 29: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 31/38
  Batch 0: Loss = 0.5320, Accuracy = 81.76%
  Batch 5: Loss = 0.1370, Accuracy = 81.92%
  Batch 10: Loss = 1.3265, Accuracy = 81.90%
  Batch 15: Loss = 0.1826, Accuracy = 81.87%
  Batch 20: Loss = 0.9251, Accuracy = 81.79%
Training on dataloader 32/38
  Batch 0: Loss = 0.2004, Accuracy = 81.84%
  Batch 5: Loss = 0.2664, Accuracy = 81.90%
  Batch 10: Loss = 0.1247, Accuracy = 82.10%
  Batch 15: Loss = 0.1386, Accuracy = 82.25%
  Batch 20: Loss = 0.7909, Accuracy = 82.33%
Training on dataloader 33/38
  Batch 0: Loss = 0.1931, Accuracy = 82.34%
  Batch 5: Loss = 0.1558, Accuracy = 82.53%
  Batch 10: Loss = 0.1253, Accuracy = 82.69%
  Batch 15: Loss = 0.1364, Accuracy = 82.82%
  Batch 20: Loss = 0.1565, Accuracy = 83.00%
Error in batch 22 of dataloader 32: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 34/38
  Batch 0: Loss = 0.6301, Accuracy = 83.04%
  Batch 5: Loss = 0.1329, Accuracy = 83.11%
  Batch 10: Loss = 0.1155, Accuracy = 83.16%
Training on dataloader 35/38
  Batch 0: Loss = 0.7598, Accuracy = 83.14%
  Batch 5: Loss = 0.3758, Accuracy = 83.21%
  Batch 10: Loss = 0.4101, Accuracy = 83.28%
Training on dataloader 36/38
  Batch 0: Loss = 0.2167, Accuracy = 83.31%
  Batch 5: Loss = 0.2327, Accuracy = 83.45%
  Batch 10: Loss = 0.1040, Accuracy = 83.56%
  Batch 15: Loss = 0.0907, Accuracy = 83.72%
  Batch 20: Loss = 0.0791, Accuracy = 83.85%
Training on dataloader 37/38
  Batch 0: Loss = 0.2304, Accuracy = 83.98%
  Batch 5: Loss = 0.0722, Accuracy = 84.08%
  Batch 10: Loss = 0.0876, Accuracy = 84.19%
  Batch 15: Loss = 0.1075, Accuracy = 84.33%
  Batch 20: Loss = 0.0706, Accuracy = 84.47%
Training on dataloader 38/38
  Batch 0: Loss = 0.0843, Accuracy = 84.50%
  Batch 5: Loss = 0.4513, Accuracy = 84.53%
  Batch 10: Loss = 0.8526, Accuracy = 84.44%

=== TRAINING EPOCH SUMMARY ===
Average Loss: 0.4852
Accuracy: 84.43%
Total Samples: 4488
==============================
Evaluating on dataloader 1/3
  Batch 0: Loss = 0.6142, Accuracy = 75.00%
  Batch 5: Loss = 0.2508, Accuracy = 68.75%
  Batch 10: Loss = 0.1814, Accuracy = 75.00%
  Batch 15: Loss = 0.1425, Accuracy = 78.12%
  Batch 20: Loss = 0.0119, Accuracy = 82.74%
Evaluating on dataloader 2/3
  Batch 0: Loss = 0.9633, Accuracy = 83.07%
  Batch 5: Loss = 0.9813, Accuracy = 79.91%
  Batch 10: Loss = 0.1068, Accuracy = 79.18%
  Batch 15: Loss = 0.7723, Accuracy = 80.26%
  Batch 20: Loss = 0.6048, Accuracy = 80.80%
  Batch 25: Loss = 0.0119, Accuracy = 82.12%
Evaluating on dataloader 3/3
  Batch 0: Loss = 1.2214, Accuracy = 81.73%
  Batch 5: Loss = 0.7463, Accuracy = 80.88%
  Batch 10: Loss = 0.9009, Accuracy = 80.17%

=== VALIDATION EPOCH SUMMARY ===
Average Loss: 0.5041
Accuracy: 79.96%
Total Samples: 484
===================================
New best validation accuracy: 79.96% - Models saved!

==================================================
EPOCH 3/20
==================================================
Training on dataloader 1/38
  Batch 0: Loss = 2.2711, Accuracy = 50.00%
  Batch 5: Loss = 1.2265, Accuracy = 79.17%
  Batch 10: Loss = 0.5293, Accuracy = 80.68%
Training on dataloader 2/38
  Batch 0: Loss = 0.6854, Accuracy = 80.39%
  Batch 5: Loss = 0.8841, Accuracy = 78.87%
  Batch 10: Loss = 2.0455, Accuracy = 75.27%
Training on dataloader 3/38
  Batch 0: Loss = 1.0438, Accuracy = 74.09%
  Batch 5: Loss = 0.3442, Accuracy = 75.54%
  Batch 10: Loss = 0.6819, Accuracy = 76.92%
Training on dataloader 4/38
  Batch 0: Loss = 0.3523, Accuracy = 77.51%
  Batch 5: Loss = 0.3761, Accuracy = 78.42%
  Batch 10: Loss = 0.4839, Accuracy = 77.78%
Training on dataloader 5/38
  Batch 0: Loss = 1.3083, Accuracy = 77.40%
  Batch 5: Loss = 0.5329, Accuracy = 76.94%
  Batch 10: Loss = 0.5891, Accuracy = 76.99%
Training on dataloader 6/38
  Batch 0: Loss = 0.1553, Accuracy = 77.43%
  Batch 5: Loss = 0.2223, Accuracy = 78.78%
  Batch 10: Loss = 0.4501, Accuracy = 78.33%
Training on dataloader 7/38
  Batch 0: Loss = 0.3428, Accuracy = 78.41%
  Batch 5: Loss = 0.3622, Accuracy = 78.03%
  Batch 10: Loss = 0.5438, Accuracy = 77.69%
Training on dataloader 8/38
  Batch 0: Loss = 1.1233, Accuracy = 77.23%
  Batch 5: Loss = 0.4588, Accuracy = 76.97%
  Batch 10: Loss = 0.8073, Accuracy = 77.13%
Training on dataloader 9/38
  Batch 0: Loss = 0.3897, Accuracy = 77.21%
  Batch 5: Loss = 0.6486, Accuracy = 76.86%
  Batch 10: Loss = 0.4280, Accuracy = 77.00%
Training on dataloader 10/38
  Batch 0: Loss = 0.4574, Accuracy = 76.97%
  Batch 5: Loss = 0.4419, Accuracy = 76.99%
  Batch 10: Loss = 0.2173, Accuracy = 77.75%
Training on dataloader 11/38
  Batch 0: Loss = 0.9852, Accuracy = 77.40%
  Batch 5: Loss = 0.9229, Accuracy = 77.40%
  Batch 10: Loss = 0.6088, Accuracy = 77.21%
Training on dataloader 12/38
  Batch 0: Loss = 0.3362, Accuracy = 77.18%
  Batch 5: Loss = 0.7638, Accuracy = 77.55%
  Batch 10: Loss = 0.7020, Accuracy = 77.46%
Training on dataloader 13/38
  Batch 0: Loss = 0.3984, Accuracy = 77.57%
  Batch 5: Loss = 0.7218, Accuracy = 77.14%
  Batch 10: Loss = 0.3253, Accuracy = 77.64%
Training on dataloader 14/38
  Batch 0: Loss = 0.3162, Accuracy = 77.73%
  Batch 5: Loss = 0.1861, Accuracy = 78.04%
  Batch 10: Loss = 0.2832, Accuracy = 78.40%
Training on dataloader 15/38
  Batch 0: Loss = 0.2765, Accuracy = 78.66%
  Batch 5: Loss = 0.1561, Accuracy = 78.91%
  Batch 10: Loss = 0.2344, Accuracy = 79.23%
  Batch 15: Loss = 0.1080, Accuracy = 79.73%
  Batch 20: Loss = 0.3277, Accuracy = 79.93%
  Batch 25: Loss = 0.1390, Accuracy = 80.39%
  Batch 30: Loss = 0.1688, Accuracy = 80.58%
Training on dataloader 16/38
  Batch 0: Loss = 1.2501, Accuracy = 80.49%
  Batch 5: Loss = 0.5338, Accuracy = 80.17%
  Batch 10: Loss = 0.6385, Accuracy = 79.93%
Training on dataloader 17/38
  Batch 0: Loss = 0.1660, Accuracy = 80.02%
  Batch 5: Loss = 1.0485, Accuracy = 80.20%
  Batch 10: Loss = 0.1515, Accuracy = 80.53%
  Batch 15: Loss = 0.1125, Accuracy = 80.97%
  Batch 20: Loss = 0.0936, Accuracy = 81.16%
Training on dataloader 18/38
  Batch 0: Loss = 0.1034, Accuracy = 81.08%
  Batch 5: Loss = 0.1416, Accuracy = 81.27%
  Batch 10: Loss = 0.1128, Accuracy = 81.24%
Training on dataloader 19/38
  Batch 0: Loss = 0.1539, Accuracy = 81.38%
  Batch 5: Loss = 0.7442, Accuracy = 81.50%
  Batch 10: Loss = 0.1351, Accuracy = 81.47%
Training on dataloader 20/38
  Batch 0: Loss = 0.1840, Accuracy = 81.49%
  Batch 5: Loss = 0.1528, Accuracy = 81.36%
  Batch 10: Loss = 0.1302, Accuracy = 81.52%
Training on dataloader 21/38
  Batch 0: Loss = 0.2143, Accuracy = 81.59%
  Batch 5: Loss = 0.2450, Accuracy = 81.92%
  Batch 10: Loss = 0.1069, Accuracy = 82.20%
  Batch 15: Loss = 0.1056, Accuracy = 82.51%
  Batch 20: Loss = 0.1293, Accuracy = 82.77%
Training on dataloader 22/38
  Batch 0: Loss = 0.2233, Accuracy = 82.99%
  Batch 5: Loss = 0.5698, Accuracy = 83.11%
  Batch 10: Loss = 0.2317, Accuracy = 83.18%
Training on dataloader 23/38
  Batch 0: Loss = 0.9172, Accuracy = 83.13%
  Batch 5: Loss = 0.1196, Accuracy = 83.24%
  Batch 10: Loss = 1.4967, Accuracy = 83.11%
Training on dataloader 24/38
  Batch 0: Loss = 0.9178, Accuracy = 82.98%
  Batch 5: Loss = 2.0181, Accuracy = 82.78%
  Batch 10: Loss = 1.1500, Accuracy = 82.51%
Training on dataloader 25/38
  Batch 0: Loss = 0.6571, Accuracy = 82.47%
  Batch 5: Loss = 0.8378, Accuracy = 82.39%
  Batch 10: Loss = 0.8912, Accuracy = 82.32%
Training on dataloader 26/38
  Batch 0: Loss = 0.1222, Accuracy = 82.41%
  Batch 5: Loss = 0.3481, Accuracy = 82.56%
  Batch 10: Loss = 0.1464, Accuracy = 82.77%
Training on dataloader 27/38
  Batch 0: Loss = 0.1015, Accuracy = 82.78%
  Batch 5: Loss = 0.1112, Accuracy = 82.99%
  Batch 10: Loss = 0.0957, Accuracy = 83.19%
  Batch 15: Loss = 0.0888, Accuracy = 83.38%
  Batch 20: Loss = 0.0837, Accuracy = 83.51%
Training on dataloader 28/38
  Batch 0: Loss = 0.0922, Accuracy = 83.59%
  Batch 5: Loss = 0.4007, Accuracy = 83.61%
  Batch 10: Loss = 0.3772, Accuracy = 83.66%
Training on dataloader 29/38
  Batch 0: Loss = 1.6708, Accuracy = 83.57%
  Batch 5: Loss = 0.6390, Accuracy = 83.56%
  Batch 10: Loss = 1.1783, Accuracy = 83.45%
Training on dataloader 30/38
  Batch 0: Loss = 0.8530, Accuracy = 83.44%
  Batch 5: Loss = 0.7160, Accuracy = 83.52%
  Batch 10: Loss = 1.2929, Accuracy = 83.41%
Error in batch 12 of dataloader 29: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 31/38
  Batch 0: Loss = 0.1848, Accuracy = 83.50%
  Batch 5: Loss = 0.1355, Accuracy = 83.69%
  Batch 10: Loss = 1.4088, Accuracy = 83.71%
  Batch 15: Loss = 0.4913, Accuracy = 83.64%
  Batch 20: Loss = 0.1061, Accuracy = 83.77%
Training on dataloader 32/38
  Batch 0: Loss = 0.1633, Accuracy = 83.91%
  Batch 5: Loss = 0.1058, Accuracy = 83.95%
  Batch 10: Loss = 0.0800, Accuracy = 84.13%
  Batch 15: Loss = 1.1889, Accuracy = 84.25%
  Batch 20: Loss = 0.3986, Accuracy = 84.34%
Training on dataloader 33/38
  Batch 0: Loss = 0.0859, Accuracy = 84.44%
  Batch 5: Loss = 0.0890, Accuracy = 84.56%
  Batch 10: Loss = 0.4160, Accuracy = 84.67%
  Batch 15: Loss = 0.0780, Accuracy = 84.83%
  Batch 20: Loss = 0.0682, Accuracy = 84.99%
Error in batch 22 of dataloader 32: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 34/38
  Batch 0: Loss = 0.6671, Accuracy = 85.00%
  Batch 5: Loss = 0.2978, Accuracy = 85.05%
  Batch 10: Loss = 0.1252, Accuracy = 85.10%
Training on dataloader 35/38
  Batch 0: Loss = 0.1849, Accuracy = 85.13%
  Batch 5: Loss = 0.1119, Accuracy = 85.20%
  Batch 10: Loss = 0.2291, Accuracy = 85.30%
Training on dataloader 36/38
  Batch 0: Loss = 0.0865, Accuracy = 85.32%
  Batch 5: Loss = 0.2385, Accuracy = 85.42%
  Batch 10: Loss = 0.0882, Accuracy = 85.54%
  Batch 15: Loss = 0.0889, Accuracy = 85.68%
  Batch 20: Loss = 0.0674, Accuracy = 85.79%
Training on dataloader 37/38
  Batch 0: Loss = 0.0736, Accuracy = 85.90%
  Batch 5: Loss = 0.0781, Accuracy = 85.96%
  Batch 10: Loss = 0.0629, Accuracy = 86.09%
  Batch 15: Loss = 0.0587, Accuracy = 86.15%
  Batch 20: Loss = 0.0835, Accuracy = 86.26%
Training on dataloader 38/38
  Batch 0: Loss = 0.3888, Accuracy = 86.30%
  Batch 5: Loss = 0.5298, Accuracy = 86.33%
  Batch 10: Loss = 0.6265, Accuracy = 86.34%

=== TRAINING EPOCH SUMMARY ===
Average Loss: 0.4339
Accuracy: 86.30%
Total Samples: 4488
==============================
Evaluating on dataloader 1/3
  Batch 0: Loss = 0.0927, Accuracy = 100.00%
  Batch 5: Loss = 0.0522, Accuracy = 100.00%
  Batch 10: Loss = 0.0455, Accuracy = 100.00%
  Batch 15: Loss = 0.8395, Accuracy = 96.88%
  Batch 20: Loss = 0.2901, Accuracy = 94.05%
Evaluating on dataloader 2/3
  Batch 0: Loss = 0.2286, Accuracy = 93.12%
  Batch 5: Loss = 0.1047, Accuracy = 94.32%
  Batch 10: Loss = 0.0357, Accuracy = 95.17%
  Batch 15: Loss = 0.7653, Accuracy = 94.82%
  Batch 20: Loss = 1.6909, Accuracy = 89.97%
  Batch 25: Loss = 0.3562, Accuracy = 88.34%
Evaluating on dataloader 3/3
  Batch 0: Loss = 0.3197, Accuracy = 88.32%
  Batch 5: Loss = 0.5387, Accuracy = 88.25%
  Batch 10: Loss = 0.3204, Accuracy = 88.40%

=== VALIDATION EPOCH SUMMARY ===
Average Loss: 0.3721
Accuracy: 88.43%
Total Samples: 484
===================================
New best validation accuracy: 88.43% - Models saved!

==================================================
EPOCH 4/20
==================================================
Training on dataloader 1/38
  Batch 0: Loss = 0.5633, Accuracy = 87.50%
  Batch 5: Loss = 0.3204, Accuracy = 83.33%
  Batch 10: Loss = 0.3495, Accuracy = 84.09%
Training on dataloader 2/38
  Batch 0: Loss = 0.9029, Accuracy = 81.37%
  Batch 5: Loss = 0.6419, Accuracy = 77.46%
  Batch 10: Loss = 1.1571, Accuracy = 76.37%
Training on dataloader 3/38
  Batch 0: Loss = 0.1229, Accuracy = 77.20%
  Batch 5: Loss = 0.3517, Accuracy = 77.68%
  Batch 10: Loss = 1.2168, Accuracy = 78.02%
Training on dataloader 4/38
  Batch 0: Loss = 0.2976, Accuracy = 78.89%
  Batch 5: Loss = 0.8433, Accuracy = 79.33%
  Batch 10: Loss = 1.0387, Accuracy = 79.13%
Training on dataloader 5/38
  Batch 0: Loss = 2.2259, Accuracy = 78.96%
  Batch 5: Loss = 1.4576, Accuracy = 78.12%
  Batch 10: Loss = 1.9139, Accuracy = 77.42%
Training on dataloader 6/38
  Batch 0: Loss = 1.9425, Accuracy = 75.57%
  Batch 5: Loss = 0.1484, Accuracy = 75.33%
  Batch 10: Loss = 0.7006, Accuracy = 75.67%
Training on dataloader 7/38
  Batch 0: Loss = 1.8453, Accuracy = 75.13%
  Batch 5: Loss = 1.3158, Accuracy = 73.99%
  Batch 10: Loss = 0.2122, Accuracy = 73.60%
Training on dataloader 8/38
  Batch 0: Loss = 0.4804, Accuracy = 73.51%
  Batch 5: Loss = 0.3465, Accuracy = 74.02%
  Batch 10: Loss = 0.5060, Accuracy = 75.00%
Training on dataloader 9/38
  Batch 0: Loss = 0.3409, Accuracy = 75.00%
  Batch 5: Loss = 0.7714, Accuracy = 74.63%
  Batch 10: Loss = 0.4088, Accuracy = 75.12%
Training on dataloader 10/38
  Batch 0: Loss = 0.2179, Accuracy = 75.35%
  Batch 5: Loss = 0.5878, Accuracy = 76.00%
  Batch 10: Loss = 1.1856, Accuracy = 76.38%
Training on dataloader 11/38
  Batch 0: Loss = 0.3472, Accuracy = 76.67%
  Batch 5: Loss = 0.4011, Accuracy = 77.10%
  Batch 10: Loss = 1.6660, Accuracy = 76.83%
Training on dataloader 12/38
  Batch 0: Loss = 0.7480, Accuracy = 76.70%
  Batch 5: Loss = 0.6998, Accuracy = 77.10%
  Batch 10: Loss = 0.1615, Accuracy = 77.29%
Training on dataloader 13/38
  Batch 0: Loss = 0.5076, Accuracy = 77.48%
  Batch 5: Loss = 0.2734, Accuracy = 77.65%
  Batch 10: Loss = 0.4393, Accuracy = 77.89%
Training on dataloader 14/38
  Batch 0: Loss = 0.1530, Accuracy = 78.05%
  Batch 5: Loss = 0.1469, Accuracy = 78.43%
  Batch 10: Loss = 0.1332, Accuracy = 79.00%
Training on dataloader 15/38
  Batch 0: Loss = 0.3776, Accuracy = 79.10%
  Batch 5: Loss = 0.2551, Accuracy = 79.57%
  Batch 10: Loss = 0.8528, Accuracy = 79.79%
  Batch 15: Loss = 0.1123, Accuracy = 79.86%
  Batch 20: Loss = 0.0987, Accuracy = 80.20%
  Batch 25: Loss = 0.2241, Accuracy = 80.52%
  Batch 30: Loss = 0.2498, Accuracy = 80.90%
Training on dataloader 16/38
  Batch 0: Loss = 0.5817, Accuracy = 80.87%
  Batch 5: Loss = 0.8922, Accuracy = 80.73%
  Batch 10: Loss = 0.2085, Accuracy = 80.65%
Training on dataloader 17/38
  Batch 0: Loss = 0.3038, Accuracy = 80.56%
  Batch 5: Loss = 0.2110, Accuracy = 80.84%
  Batch 10: Loss = 0.1284, Accuracy = 81.16%
  Batch 15: Loss = 0.1552, Accuracy = 81.58%
  Batch 20: Loss = 0.0985, Accuracy = 81.81%
Training on dataloader 18/38
  Batch 0: Loss = 0.8522, Accuracy = 81.83%
  Batch 5: Loss = 0.1927, Accuracy = 81.95%
  Batch 10: Loss = 0.1497, Accuracy = 82.22%
Training on dataloader 19/38
  Batch 0: Loss = 0.3609, Accuracy = 82.24%
  Batch 5: Loss = 0.1021, Accuracy = 82.50%
  Batch 10: Loss = 0.1324, Accuracy = 82.75%
Training on dataloader 20/38
  Batch 0: Loss = 0.5231, Accuracy = 82.75%
  Batch 5: Loss = 0.3154, Accuracy = 82.75%
  Batch 10: Loss = 0.6975, Accuracy = 82.79%
Training on dataloader 21/38
  Batch 0: Loss = 0.1104, Accuracy = 82.84%
  Batch 5: Loss = 0.1039, Accuracy = 83.11%
  Batch 10: Loss = 0.0995, Accuracy = 83.41%
  Batch 15: Loss = 0.1073, Accuracy = 83.70%
  Batch 20: Loss = 0.0907, Accuracy = 83.98%
Training on dataloader 22/38
  Batch 0: Loss = 0.1599, Accuracy = 84.23%
  Batch 5: Loss = 0.3136, Accuracy = 84.36%
  Batch 10: Loss = 0.6527, Accuracy = 84.54%
Training on dataloader 23/38
  Batch 0: Loss = 0.5220, Accuracy = 84.56%
  Batch 5: Loss = 0.1453, Accuracy = 84.49%
  Batch 10: Loss = 1.0093, Accuracy = 84.53%
Training on dataloader 24/38
  Batch 0: Loss = 0.2115, Accuracy = 84.55%
  Batch 5: Loss = 0.1081, Accuracy = 84.48%
  Batch 10: Loss = 0.4500, Accuracy = 84.41%
Training on dataloader 25/38
  Batch 0: Loss = 1.3316, Accuracy = 84.25%
  Batch 5: Loss = 2.4573, Accuracy = 83.48%
  Batch 10: Loss = 1.8069, Accuracy = 82.91%
Training on dataloader 26/38
  Batch 0: Loss = 0.8360, Accuracy = 82.81%
  Batch 5: Loss = 0.6206, Accuracy = 82.63%
  Batch 10: Loss = 0.3859, Accuracy = 82.48%
Training on dataloader 27/38
  Batch 0: Loss = 1.1798, Accuracy = 82.39%
  Batch 5: Loss = 0.8852, Accuracy = 82.05%
  Batch 10: Loss = 0.6514, Accuracy = 81.74%
  Batch 15: Loss = 0.6320, Accuracy = 81.52%
  Batch 20: Loss = 0.7149, Accuracy = 81.26%
Training on dataloader 28/38
  Batch 0: Loss = 0.9597, Accuracy = 81.05%
  Batch 5: Loss = 0.7209, Accuracy = 80.94%
  Batch 10: Loss = 0.5426, Accuracy = 80.83%
Training on dataloader 29/38
  Batch 0: Loss = 0.4556, Accuracy = 80.85%
  Batch 5: Loss = 0.9873, Accuracy = 80.75%
  Batch 10: Loss = 0.5038, Accuracy = 80.58%
Training on dataloader 30/38
  Batch 0: Loss = 0.4687, Accuracy = 80.61%
  Batch 5: Loss = 0.8202, Accuracy = 80.36%
  Batch 10: Loss = 0.6978, Accuracy = 80.14%
Error in batch 12 of dataloader 29: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 31/38
  Batch 0: Loss = 0.6600, Accuracy = 80.18%
  Batch 5: Loss = 0.3234, Accuracy = 80.05%
  Batch 10: Loss = 0.4967, Accuracy = 80.11%
  Batch 15: Loss = 0.4329, Accuracy = 80.08%
  Batch 20: Loss = 0.2340, Accuracy = 80.17%
Training on dataloader 32/38
  Batch 0: Loss = 0.4207, Accuracy = 80.25%
  Batch 5: Loss = 0.1723, Accuracy = 80.36%
  Batch 10: Loss = 0.2491, Accuracy = 80.53%
  Batch 15: Loss = 0.2468, Accuracy = 80.72%
  Batch 20: Loss = 0.3607, Accuracy = 80.90%
Training on dataloader 33/38
  Batch 0: Loss = 0.4447, Accuracy = 81.00%
  Batch 5: Loss = 0.1334, Accuracy = 81.17%
  Batch 10: Loss = 0.0860, Accuracy = 81.38%
  Batch 15: Loss = 0.0757, Accuracy = 81.57%
  Batch 20: Loss = 0.0821, Accuracy = 81.74%
Error in batch 22 of dataloader 32: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 34/38
  Batch 0: Loss = 1.5539, Accuracy = 81.74%
  Batch 5: Loss = 1.1731, Accuracy = 81.67%
  Batch 10: Loss = 1.6834, Accuracy = 81.50%
Training on dataloader 35/38
  Batch 0: Loss = 1.7451, Accuracy = 81.44%
  Batch 5: Loss = 0.4131, Accuracy = 81.30%
  Batch 10: Loss = 0.3457, Accuracy = 81.23%
Training on dataloader 36/38
  Batch 0: Loss = 0.1121, Accuracy = 81.27%
  Batch 5: Loss = 0.1120, Accuracy = 81.40%
  Batch 10: Loss = 0.1168, Accuracy = 81.59%
  Batch 15: Loss = 0.2570, Accuracy = 81.76%
  Batch 20: Loss = 0.1161, Accuracy = 81.94%
Training on dataloader 37/38
  Batch 0: Loss = 0.3530, Accuracy = 82.06%
  Batch 5: Loss = 0.4473, Accuracy = 81.97%
  Batch 10: Loss = 1.2080, Accuracy = 82.02%
  Batch 15: Loss = 0.0959, Accuracy = 82.12%
  Batch 20: Loss = 0.2361, Accuracy = 82.26%
Training on dataloader 38/38
  Batch 0: Loss = 0.1347, Accuracy = 82.34%
  Batch 5: Loss = 1.0037, Accuracy = 82.27%
  Batch 10: Loss = 0.5522, Accuracy = 82.12%

=== TRAINING EPOCH SUMMARY ===
Average Loss: 0.5011
Accuracy: 82.13%
Total Samples: 4488
==============================
Evaluating on dataloader 1/3
  Batch 0: Loss = 0.1911, Accuracy = 87.50%
  Batch 5: Loss = 0.0707, Accuracy = 95.83%
  Batch 10: Loss = 0.0988, Accuracy = 97.73%
  Batch 15: Loss = 0.9183, Accuracy = 91.41%
  Batch 20: Loss = 0.3154, Accuracy = 85.71%
Evaluating on dataloader 2/3
  Batch 0: Loss = 0.2074, Accuracy = 85.19%
  Batch 5: Loss = 0.3167, Accuracy = 87.77%
  Batch 10: Loss = 0.0991, Accuracy = 88.85%
  Batch 15: Loss = 1.6342, Accuracy = 87.06%
  Batch 20: Loss = 3.1050, Accuracy = 79.37%
  Batch 25: Loss = 0.9658, Accuracy = 75.65%
Evaluating on dataloader 3/3
  Batch 0: Loss = 0.6301, Accuracy = 75.13%
  Batch 5: Loss = 0.7802, Accuracy = 74.65%
  Batch 10: Loss = 0.2086, Accuracy = 75.74%

=== VALIDATION EPOCH SUMMARY ===
Average Loss: 0.7373
Accuracy: 76.24%
Total Samples: 484
===================================
No improvement in validation accuracy. Patience: 1/5

==================================================
EPOCH 5/20
==================================================
Training on dataloader 1/38
  Batch 0: Loss = 0.2674, Accuracy = 100.00%
  Batch 5: Loss = 0.8154, Accuracy = 77.08%
  Batch 10: Loss = 0.5815, Accuracy = 72.73%
Training on dataloader 2/38
  Batch 0: Loss = 0.8101, Accuracy = 71.57%
  Batch 5: Loss = 0.6437, Accuracy = 73.94%
  Batch 10: Loss = 0.8761, Accuracy = 71.43%
Training on dataloader 3/38
  Batch 0: Loss = 0.3821, Accuracy = 72.02%
  Batch 5: Loss = 0.8365, Accuracy = 72.53%
  Batch 10: Loss = 0.4885, Accuracy = 75.46%
Training on dataloader 4/38
  Batch 0: Loss = 0.2464, Accuracy = 76.12%
  Batch 5: Loss = 0.4383, Accuracy = 78.12%
  Batch 10: Loss = 0.5262, Accuracy = 79.13%
Training on dataloader 5/38
  Batch 0: Loss = 0.4088, Accuracy = 79.48%
  Batch 5: Loss = 0.7270, Accuracy = 78.82%
  Batch 10: Loss = 0.7570, Accuracy = 78.71%
Training on dataloader 6/38
  Batch 0: Loss = 0.2097, Accuracy = 79.30%
  Batch 5: Loss = 0.4383, Accuracy = 80.31%
  Batch 10: Loss = 0.5116, Accuracy = 80.46%
Training on dataloader 7/38
  Batch 0: Loss = 1.0659, Accuracy = 80.48%
  Batch 5: Loss = 0.2550, Accuracy = 80.13%
  Batch 10: Loss = 0.2863, Accuracy = 80.12%
Training on dataloader 8/38
  Batch 0: Loss = 0.4605, Accuracy = 79.76%
  Batch 5: Loss = 0.3330, Accuracy = 80.06%
  Batch 10: Loss = 0.4127, Accuracy = 80.59%
Training on dataloader 9/38
  Batch 0: Loss = 0.6842, Accuracy = 80.60%
  Batch 5: Loss = 0.1827, Accuracy = 80.94%
  Batch 10: Loss = 0.3434, Accuracy = 80.78%
Training on dataloader 10/38
  Batch 0: Loss = 0.2571, Accuracy = 80.79%
  Batch 5: Loss = 0.8932, Accuracy = 80.97%
  Batch 10: Loss = 0.3938, Accuracy = 80.93%
Training on dataloader 11/38
  Batch 0: Loss = 1.2949, Accuracy = 80.73%
  Batch 5: Loss = 0.4239, Accuracy = 80.50%
  Batch 10: Loss = 0.2144, Accuracy = 80.58%
Training on dataloader 12/38
  Batch 0: Loss = 1.3041, Accuracy = 80.11%
  Batch 5: Loss = 0.2439, Accuracy = 80.20%
  Batch 10: Loss = 0.3211, Accuracy = 80.81%
Training on dataloader 13/38
  Batch 0: Loss = 0.1512, Accuracy = 80.96%
  Batch 5: Loss = 0.6455, Accuracy = 80.92%
  Batch 10: Loss = 1.0815, Accuracy = 80.73%
Training on dataloader 14/38
  Batch 0: Loss = 0.2050, Accuracy = 80.79%
  Batch 5: Loss = 0.4394, Accuracy = 80.76%
  Batch 10: Loss = 0.3808, Accuracy = 81.19%
Training on dataloader 15/38
  Batch 0: Loss = 0.1338, Accuracy = 81.42%
  Batch 5: Loss = 0.1795, Accuracy = 81.59%
  Batch 10: Loss = 0.1766, Accuracy = 81.76%
  Batch 15: Loss = 0.1298, Accuracy = 82.12%
  Batch 20: Loss = 0.7135, Accuracy = 82.33%
  Batch 25: Loss = 0.1386, Accuracy = 82.60%
  Batch 30: Loss = 0.2600, Accuracy = 82.93%
Training on dataloader 16/38
  Batch 0: Loss = 0.1808, Accuracy = 82.95%
  Batch 5: Loss = 0.6578, Accuracy = 82.82%
  Batch 10: Loss = 1.4315, Accuracy = 82.69%
Training on dataloader 17/38
  Batch 0: Loss = 0.1307, Accuracy = 82.52%
  Batch 5: Loss = 0.3393, Accuracy = 82.58%
  Batch 10: Loss = 0.3085, Accuracy = 82.80%
  Batch 15: Loss = 0.2250, Accuracy = 82.69%
  Batch 20: Loss = 0.5126, Accuracy = 82.90%
Training on dataloader 18/38
  Batch 0: Loss = 0.4377, Accuracy = 83.07%
  Batch 5: Loss = 0.2489, Accuracy = 82.95%
  Batch 10: Loss = 0.1889, Accuracy = 83.09%
Training on dataloader 19/38
  Batch 0: Loss = 0.1276, Accuracy = 83.21%
  Batch 5: Loss = 0.1516, Accuracy = 83.50%
  Batch 10: Loss = 0.7830, Accuracy = 83.38%
Training on dataloader 20/38
  Batch 0: Loss = 0.4508, Accuracy = 83.43%
  Batch 5: Loss = 0.1094, Accuracy = 83.46%
  Batch 10: Loss = 0.1236, Accuracy = 83.68%
Training on dataloader 21/38
  Batch 0: Loss = 0.1114, Accuracy = 83.77%
  Batch 5: Loss = 0.1000, Accuracy = 84.02%
  Batch 10: Loss = 0.1068, Accuracy = 84.21%
  Batch 15: Loss = 0.1139, Accuracy = 84.49%
  Batch 20: Loss = 0.1035, Accuracy = 84.72%
Training on dataloader 22/38
  Batch 0: Loss = 0.1068, Accuracy = 84.74%
  Batch 5: Loss = 0.3212, Accuracy = 84.82%
  Batch 10: Loss = 0.1930, Accuracy = 84.79%
Training on dataloader 23/38
  Batch 0: Loss = 0.7428, Accuracy = 84.76%
  Batch 5: Loss = 0.1386, Accuracy = 84.89%
  Batch 10: Loss = 0.2869, Accuracy = 84.93%
Training on dataloader 24/38
  Batch 0: Loss = 0.3656, Accuracy = 84.91%
  Batch 5: Loss = 1.1646, Accuracy = 84.75%
  Batch 10: Loss = 0.3197, Accuracy = 84.64%
Training on dataloader 25/38
  Batch 0: Loss = 0.3705, Accuracy = 84.63%
  Batch 5: Loss = 0.1906, Accuracy = 84.52%
  Batch 10: Loss = 0.5947, Accuracy = 84.49%
Training on dataloader 26/38
  Batch 0: Loss = 0.3485, Accuracy = 84.46%
  Batch 5: Loss = 0.1435, Accuracy = 84.51%
  Batch 10: Loss = 0.1154, Accuracy = 84.62%
Training on dataloader 27/38
  Batch 0: Loss = 0.1133, Accuracy = 84.66%
  Batch 5: Loss = 0.1937, Accuracy = 84.84%
  Batch 10: Loss = 0.2188, Accuracy = 84.98%
  Batch 15: Loss = 0.1358, Accuracy = 85.15%
  Batch 20: Loss = 0.3895, Accuracy = 85.28%
Training on dataloader 28/38
  Batch 0: Loss = 0.0881, Accuracy = 85.36%
  Batch 5: Loss = 0.7606, Accuracy = 85.45%
  Batch 10: Loss = 0.1347, Accuracy = 85.45%
Training on dataloader 29/38
  Batch 0: Loss = 1.1792, Accuracy = 85.38%
  Batch 5: Loss = 0.4472, Accuracy = 85.12%
  Batch 10: Loss = 0.8386, Accuracy = 85.03%
Training on dataloader 30/38
  Batch 0: Loss = 0.9791, Accuracy = 84.91%
  Batch 5: Loss = 0.7736, Accuracy = 84.82%
  Batch 10: Loss = 1.1586, Accuracy = 84.58%
Error in batch 12 of dataloader 29: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 31/38
  Batch 0: Loss = 0.5076, Accuracy = 84.59%
  Batch 5: Loss = 0.2338, Accuracy = 84.60%
  Batch 10: Loss = 0.1601, Accuracy = 84.75%
  Batch 15: Loss = 0.2879, Accuracy = 84.90%
  Batch 20: Loss = 0.1315, Accuracy = 85.05%
Training on dataloader 32/38
  Batch 0: Loss = 0.1738, Accuracy = 85.18%
  Batch 5: Loss = 0.2844, Accuracy = 85.26%
  Batch 10: Loss = 0.1248, Accuracy = 85.42%
  Batch 15: Loss = 0.7798, Accuracy = 85.48%
  Batch 20: Loss = 0.1105, Accuracy = 85.61%
Training on dataloader 33/38
  Batch 0: Loss = 0.0725, Accuracy = 85.70%
  Batch 5: Loss = 0.0746, Accuracy = 85.80%
  Batch 10: Loss = 0.2214, Accuracy = 85.92%
  Batch 15: Loss = 0.3553, Accuracy = 86.02%
  Batch 20: Loss = 0.0678, Accuracy = 86.11%
Error in batch 22 of dataloader 32: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 34/38
  Batch 0: Loss = 0.7637, Accuracy = 86.12%
  Batch 5: Loss = 0.0959, Accuracy = 86.13%
  Batch 10: Loss = 1.0719, Accuracy = 86.10%
Training on dataloader 35/38
  Batch 0: Loss = 0.5072, Accuracy = 86.07%
  Batch 5: Loss = 0.1496, Accuracy = 86.06%
  Batch 10: Loss = 0.1037, Accuracy = 86.02%
Training on dataloader 36/38
  Batch 0: Loss = 0.1041, Accuracy = 86.04%
  Batch 5: Loss = 0.1021, Accuracy = 86.08%
  Batch 10: Loss = 0.1996, Accuracy = 86.22%
  Batch 15: Loss = 0.1091, Accuracy = 86.23%
  Batch 20: Loss = 0.1131, Accuracy = 86.32%
Training on dataloader 37/38
  Batch 0: Loss = 0.4334, Accuracy = 86.42%
  Batch 5: Loss = 1.3580, Accuracy = 86.46%
  Batch 10: Loss = 0.2235, Accuracy = 86.51%
  Batch 15: Loss = 0.9716, Accuracy = 86.45%
  Batch 20: Loss = 0.0891, Accuracy = 86.51%
Training on dataloader 38/38
  Batch 0: Loss = 1.6349, Accuracy = 86.45%
  Batch 5: Loss = 0.0905, Accuracy = 86.37%
  Batch 10: Loss = 0.5918, Accuracy = 86.41%

=== TRAINING EPOCH SUMMARY ===
Average Loss: 0.3976
Accuracy: 86.39%
Total Samples: 4488
==============================
Evaluating on dataloader 1/3
  Batch 0: Loss = 0.0945, Accuracy = 100.00%
  Batch 5: Loss = 0.0943, Accuracy = 93.75%
  Batch 10: Loss = 0.0871, Accuracy = 96.59%
  Batch 15: Loss = 0.3559, Accuracy = 95.31%
  Batch 20: Loss = 0.2173, Accuracy = 93.45%
Evaluating on dataloader 2/3
  Batch 0: Loss = 0.2180, Accuracy = 92.59%
  Batch 5: Loss = 0.0521, Accuracy = 93.45%
  Batch 10: Loss = 0.0648, Accuracy = 94.05%
  Batch 15: Loss = 0.4975, Accuracy = 94.17%
  Batch 20: Loss = 1.0517, Accuracy = 91.40%
  Batch 25: Loss = 0.2828, Accuracy = 90.41%
Evaluating on dataloader 3/3
  Batch 0: Loss = 0.1103, Accuracy = 90.61%
  Batch 5: Loss = 0.4272, Accuracy = 90.78%
  Batch 10: Loss = 0.2921, Accuracy = 90.72%

=== VALIDATION EPOCH SUMMARY ===
Average Loss: 0.2439
Accuracy: 90.70%
Total Samples: 484
===================================
New best validation accuracy: 90.70% - Models saved!

==================================================
EPOCH 6/20
==================================================
Training on dataloader 1/38
  Batch 0: Loss = 0.1285, Accuracy = 100.00%
  Batch 5: Loss = 0.8130, Accuracy = 87.50%
  Batch 10: Loss = 0.1356, Accuracy = 84.09%
Training on dataloader 2/38
  Batch 0: Loss = 1.8077, Accuracy = 80.39%
  Batch 5: Loss = 0.5417, Accuracy = 81.69%
  Batch 10: Loss = 0.4401, Accuracy = 79.67%
Training on dataloader 3/38
  Batch 0: Loss = 0.4607, Accuracy = 79.27%
  Batch 5: Loss = 0.6143, Accuracy = 79.83%
  Batch 10: Loss = 0.1417, Accuracy = 79.12%
Training on dataloader 4/38
  Batch 0: Loss = 0.1843, Accuracy = 79.93%
  Batch 5: Loss = 0.6298, Accuracy = 80.85%
  Batch 10: Loss = 0.1296, Accuracy = 81.84%
Training on dataloader 5/38
  Batch 0: Loss = 0.6126, Accuracy = 81.82%
  Batch 5: Loss = 0.6583, Accuracy = 81.65%
  Batch 10: Loss = 0.9190, Accuracy = 81.29%
Training on dataloader 6/38
  Batch 0: Loss = 0.3935, Accuracy = 81.37%
  Batch 5: Loss = 0.6099, Accuracy = 80.88%
  Batch 10: Loss = 0.1529, Accuracy = 80.82%
Training on dataloader 7/38
  Batch 0: Loss = 0.2794, Accuracy = 80.83%
  Batch 5: Loss = 0.8156, Accuracy = 80.45%
  Batch 10: Loss = 0.6957, Accuracy = 79.97%
Training on dataloader 8/38
  Batch 0: Loss = 0.1988, Accuracy = 80.21%
  Batch 5: Loss = 0.2018, Accuracy = 80.34%
  Batch 10: Loss = 0.3021, Accuracy = 80.32%
Training on dataloader 9/38
  Batch 0: Loss = 0.3465, Accuracy = 80.47%
  Batch 5: Loss = 0.5201, Accuracy = 80.07%
  Batch 10: Loss = 0.7028, Accuracy = 79.48%
Training on dataloader 10/38
  Batch 0: Loss = 0.5808, Accuracy = 79.28%
  Batch 5: Loss = 0.7708, Accuracy = 78.87%
  Batch 10: Loss = 0.4945, Accuracy = 78.81%
Training on dataloader 11/38
  Batch 0: Loss = 0.6620, Accuracy = 78.85%
  Batch 5: Loss = 0.5037, Accuracy = 78.80%
  Batch 10: Loss = 0.3927, Accuracy = 78.56%
Training on dataloader 12/38
  Batch 0: Loss = 0.2709, Accuracy = 78.88%
  Batch 5: Loss = 0.2212, Accuracy = 79.47%
  Batch 10: Loss = 0.3273, Accuracy = 79.93%
Training on dataloader 13/38
  Batch 0: Loss = 0.5590, Accuracy = 80.00%
  Batch 5: Loss = 0.3980, Accuracy = 80.00%
  Batch 10: Loss = 1.2340, Accuracy = 79.76%
Training on dataloader 14/38
  Batch 0: Loss = 0.8546, Accuracy = 79.66%
  Batch 5: Loss = 0.3023, Accuracy = 79.91%
  Batch 10: Loss = 0.1980, Accuracy = 80.44%
Training on dataloader 15/38
  Batch 0: Loss = 0.5582, Accuracy = 80.45%
  Batch 5: Loss = 0.2626, Accuracy = 80.65%
  Batch 10: Loss = 0.6589, Accuracy = 80.92%
  Batch 15: Loss = 0.2378, Accuracy = 81.30%
  Batch 20: Loss = 0.1448, Accuracy = 81.73%
  Batch 25: Loss = 0.3108, Accuracy = 81.95%
  Batch 30: Loss = 0.1562, Accuracy = 82.11%
Training on dataloader 16/38
  Batch 0: Loss = 0.3587, Accuracy = 82.07%
  Batch 5: Loss = 0.6825, Accuracy = 82.08%
  Batch 10: Loss = 1.1031, Accuracy = 81.67%
Training on dataloader 17/38
  Batch 0: Loss = 0.2401, Accuracy = 81.81%
  Batch 5: Loss = 0.1362, Accuracy = 82.11%
  Batch 10: Loss = 0.1361, Accuracy = 82.52%
  Batch 15: Loss = 0.6559, Accuracy = 82.57%
  Batch 20: Loss = 0.2222, Accuracy = 82.68%
Training on dataloader 18/38
  Batch 0: Loss = 0.8808, Accuracy = 82.74%
  Batch 5: Loss = 0.5429, Accuracy = 82.95%
  Batch 10: Loss = 0.3539, Accuracy = 83.20%
Training on dataloader 19/38
  Batch 0: Loss = 0.4944, Accuracy = 83.11%
  Batch 5: Loss = 0.3523, Accuracy = 83.30%
  Batch 10: Loss = 0.4496, Accuracy = 83.28%
Training on dataloader 20/38
  Batch 0: Loss = 0.5121, Accuracy = 83.28%
  Batch 5: Loss = 0.9641, Accuracy = 82.75%
  Batch 10: Loss = 0.6784, Accuracy = 82.41%
Training on dataloader 21/38
  Batch 0: Loss = 0.1318, Accuracy = 82.51%
  Batch 5: Loss = 0.1478, Accuracy = 82.65%
  Batch 10: Loss = 0.7547, Accuracy = 82.87%
  Batch 15: Loss = 0.1203, Accuracy = 83.08%
  Batch 20: Loss = 0.1222, Accuracy = 83.38%
Training on dataloader 22/38
  Batch 0: Loss = 0.2586, Accuracy = 83.59%
  Batch 5: Loss = 0.1051, Accuracy = 83.82%
  Batch 10: Loss = 0.3145, Accuracy = 83.92%
Training on dataloader 23/38
  Batch 0: Loss = 0.1677, Accuracy = 84.03%
  Batch 5: Loss = 0.6421, Accuracy = 84.12%
  Batch 10: Loss = 0.3559, Accuracy = 84.18%
Training on dataloader 24/38
  Batch 0: Loss = 0.2659, Accuracy = 84.20%
  Batch 5: Loss = 0.7948, Accuracy = 83.94%
  Batch 10: Loss = 0.2646, Accuracy = 83.99%
Training on dataloader 25/38
  Batch 0: Loss = 0.3898, Accuracy = 83.98%
  Batch 5: Loss = 0.1676, Accuracy = 84.00%
  Batch 10: Loss = 0.1530, Accuracy = 84.05%
Training on dataloader 26/38
  Batch 0: Loss = 0.5295, Accuracy = 84.02%
  Batch 5: Loss = 0.9588, Accuracy = 84.07%
  Batch 10: Loss = 0.1963, Accuracy = 84.16%
Training on dataloader 27/38
  Batch 0: Loss = 0.1153, Accuracy = 84.20%
  Batch 5: Loss = 0.0968, Accuracy = 84.39%
  Batch 10: Loss = 0.0986, Accuracy = 84.57%
  Batch 15: Loss = 0.0844, Accuracy = 84.51%
  Batch 20: Loss = 0.0934, Accuracy = 84.68%
Training on dataloader 28/38
  Batch 0: Loss = 1.1439, Accuracy = 84.66%
  Batch 5: Loss = 0.5869, Accuracy = 84.63%
  Batch 10: Loss = 0.1586, Accuracy = 84.70%
Training on dataloader 29/38
  Batch 0: Loss = 0.1796, Accuracy = 84.73%
  Batch 5: Loss = 0.4400, Accuracy = 84.58%
  Batch 10: Loss = 0.8729, Accuracy = 84.43%
Training on dataloader 30/38
  Batch 0: Loss = 0.3625, Accuracy = 84.44%
  Batch 5: Loss = 0.5256, Accuracy = 84.29%
  Batch 10: Loss = 0.7390, Accuracy = 84.27%
Error in batch 12 of dataloader 29: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 31/38
  Batch 0: Loss = 0.4906, Accuracy = 84.32%
  Batch 5: Loss = 0.1812, Accuracy = 84.33%
  Batch 10: Loss = 0.1623, Accuracy = 84.42%
  Batch 15: Loss = 0.1623, Accuracy = 84.55%
  Batch 20: Loss = 0.1096, Accuracy = 84.61%
Training on dataloader 32/38
  Batch 0: Loss = 0.1105, Accuracy = 84.69%
  Batch 5: Loss = 0.1057, Accuracy = 84.80%
  Batch 10: Loss = 0.1321, Accuracy = 84.92%
  Batch 15: Loss = 0.0855, Accuracy = 85.09%
  Batch 20: Loss = 0.5691, Accuracy = 85.20%
Training on dataloader 33/38
  Batch 0: Loss = 0.0827, Accuracy = 85.26%
  Batch 5: Loss = 0.3752, Accuracy = 85.39%
  Batch 10: Loss = 0.0787, Accuracy = 85.52%
  Batch 15: Loss = 0.3325, Accuracy = 85.54%
  Batch 20: Loss = 0.1224, Accuracy = 85.54%
Error in batch 22 of dataloader 32: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 34/38
  Batch 0: Loss = 0.2134, Accuracy = 85.57%
  Batch 5: Loss = 0.4825, Accuracy = 85.62%
  Batch 10: Loss = 0.0975, Accuracy = 85.46%
Training on dataloader 35/38
  Batch 0: Loss = 0.0788, Accuracy = 85.51%
  Batch 5: Loss = 1.0553, Accuracy = 85.51%
  Batch 10: Loss = 0.6945, Accuracy = 85.53%
Training on dataloader 36/38
  Batch 0: Loss = 0.2762, Accuracy = 85.52%
  Batch 5: Loss = 0.1314, Accuracy = 85.49%
  Batch 10: Loss = 0.3721, Accuracy = 85.54%
  Batch 15: Loss = 0.5240, Accuracy = 85.60%
  Batch 20: Loss = 0.0838, Accuracy = 85.69%
Training on dataloader 37/38
  Batch 0: Loss = 0.0842, Accuracy = 85.76%
  Batch 5: Loss = 0.1109, Accuracy = 85.89%
  Batch 10: Loss = 0.0745, Accuracy = 85.98%
  Batch 15: Loss = 0.0785, Accuracy = 86.08%
  Batch 20: Loss = 0.0773, Accuracy = 86.21%
Training on dataloader 38/38
  Batch 0: Loss = 0.6872, Accuracy = 86.20%
  Batch 5: Loss = 0.1404, Accuracy = 86.19%
  Batch 10: Loss = 0.4346, Accuracy = 86.14%

=== TRAINING EPOCH SUMMARY ===
Average Loss: 0.4057
Accuracy: 86.12%
Total Samples: 4488
==============================
Evaluating on dataloader 1/3
  Batch 0: Loss = 0.1530, Accuracy = 100.00%
  Batch 5: Loss = 0.1284, Accuracy = 100.00%
  Batch 10: Loss = 0.1265, Accuracy = 100.00%
  Batch 15: Loss = 0.2363, Accuracy = 99.22%
  Batch 20: Loss = 0.1340, Accuracy = 98.81%
Evaluating on dataloader 2/3
  Batch 0: Loss = 0.3248, Accuracy = 98.41%
  Batch 5: Loss = 0.1870, Accuracy = 98.25%
  Batch 10: Loss = 0.1069, Accuracy = 98.51%
  Batch 15: Loss = 0.5149, Accuracy = 98.06%
  Batch 20: Loss = 0.6892, Accuracy = 95.70%
  Batch 25: Loss = 0.1444, Accuracy = 95.60%
Evaluating on dataloader 3/3
  Batch 0: Loss = 0.2230, Accuracy = 95.69%
  Batch 5: Loss = 0.4321, Accuracy = 95.16%
  Batch 10: Loss = 0.4274, Accuracy = 94.51%

=== VALIDATION EPOCH SUMMARY ===
Average Loss: 0.2333
Accuracy: 94.42%
Total Samples: 484
===================================
New best validation accuracy: 94.42% - Models saved!

==================================================
EPOCH 7/20
==================================================
Training on dataloader 1/38
  Batch 0: Loss = 0.1240, Accuracy = 100.00%
  Batch 5: Loss = 0.1364, Accuracy = 91.67%
  Batch 10: Loss = 0.2446, Accuracy = 87.50%
Training on dataloader 2/38
  Batch 0: Loss = 0.1662, Accuracy = 87.25%
  Batch 5: Loss = 0.1495, Accuracy = 85.92%
  Batch 10: Loss = 0.1186, Accuracy = 80.77%
Training on dataloader 3/38
  Batch 0: Loss = 0.1211, Accuracy = 80.83%
  Batch 5: Loss = 0.5757, Accuracy = 82.40%
  Batch 10: Loss = 0.5051, Accuracy = 82.05%
Training on dataloader 4/38
  Batch 0: Loss = 0.3088, Accuracy = 82.35%
  Batch 5: Loss = 0.1743, Accuracy = 83.28%
  Batch 10: Loss = 0.1286, Accuracy = 83.47%
Training on dataloader 5/38
  Batch 0: Loss = 0.5527, Accuracy = 83.38%
  Batch 5: Loss = 0.6668, Accuracy = 83.29%
  Batch 10: Loss = 0.5319, Accuracy = 81.08%
Training on dataloader 6/38
  Batch 0: Loss = 0.3620, Accuracy = 80.95%
  Batch 5: Loss = 0.2035, Accuracy = 80.88%
  Batch 10: Loss = 0.1226, Accuracy = 81.53%
Training on dataloader 7/38
  Batch 0: Loss = 0.5845, Accuracy = 81.17%
  Batch 5: Loss = 0.5173, Accuracy = 80.29%
  Batch 10: Loss = 0.6401, Accuracy = 80.12%
Training on dataloader 8/38
  Batch 0: Loss = 0.4854, Accuracy = 79.91%
  Batch 5: Loss = 0.5958, Accuracy = 79.63%
  Batch 10: Loss = 0.5615, Accuracy = 79.92%
Training on dataloader 9/38
  Batch 0: Loss = 0.1439, Accuracy = 80.34%
  Batch 5: Loss = 0.4096, Accuracy = 80.20%
  Batch 10: Loss = 0.8328, Accuracy = 79.48%
Training on dataloader 10/38
  Batch 0: Loss = 0.6645, Accuracy = 79.17%
  Batch 5: Loss = 0.2469, Accuracy = 78.76%
  Batch 10: Loss = 0.4492, Accuracy = 78.39%
Training on dataloader 11/38
  Batch 0: Loss = 0.7557, Accuracy = 78.12%
  Batch 5: Loss = 0.4874, Accuracy = 77.80%
  Batch 10: Loss = 0.9636, Accuracy = 77.31%
Training on dataloader 12/38
  Batch 0: Loss = 0.4336, Accuracy = 77.27%
  Batch 5: Loss = 0.4434, Accuracy = 77.74%
  Batch 10: Loss = 0.4999, Accuracy = 78.08%
Training on dataloader 13/38
  Batch 0: Loss = 0.7688, Accuracy = 78.09%
  Batch 5: Loss = 0.3548, Accuracy = 78.24%
  Batch 10: Loss = 0.8276, Accuracy = 78.29%
Training on dataloader 14/38
  Batch 0: Loss = 0.1760, Accuracy = 78.38%
  Batch 5: Loss = 0.1564, Accuracy = 78.58%
  Batch 10: Loss = 0.4390, Accuracy = 78.78%
Training on dataloader 15/38
  Batch 0: Loss = 0.5088, Accuracy = 78.88%
  Batch 5: Loss = 0.2460, Accuracy = 79.06%
  Batch 10: Loss = 0.2551, Accuracy = 79.51%
  Batch 15: Loss = 0.1526, Accuracy = 79.86%
  Batch 20: Loss = 0.3211, Accuracy = 80.20%
  Batch 25: Loss = 0.2126, Accuracy = 80.58%
  Batch 30: Loss = 0.3408, Accuracy = 80.84%
Training on dataloader 16/38
  Batch 0: Loss = 0.9084, Accuracy = 80.81%
  Batch 5: Loss = 0.7454, Accuracy = 80.73%
  Batch 10: Loss = 0.8354, Accuracy = 80.05%
Training on dataloader 17/38
  Batch 0: Loss = 0.3456, Accuracy = 79.90%
  Batch 5: Loss = 0.4054, Accuracy = 80.20%
  Batch 10: Loss = 0.3580, Accuracy = 80.31%
  Batch 15: Loss = 0.2399, Accuracy = 80.41%
  Batch 20: Loss = 0.1311, Accuracy = 80.73%
Training on dataloader 18/38
  Batch 0: Loss = 0.4945, Accuracy = 80.92%
  Batch 5: Loss = 0.2181, Accuracy = 81.06%
  Batch 10: Loss = 0.4546, Accuracy = 81.09%
Training on dataloader 19/38
  Batch 0: Loss = 0.3315, Accuracy = 81.07%
  Batch 5: Loss = 0.1354, Accuracy = 81.25%
  Batch 10: Loss = 0.1475, Accuracy = 81.52%
Training on dataloader 20/38
  Batch 0: Loss = 0.4163, Accuracy = 81.58%
  Batch 5: Loss = 0.1929, Accuracy = 81.55%
  Batch 10: Loss = 0.1152, Accuracy = 81.76%
Training on dataloader 21/38
  Batch 0: Loss = 0.1301, Accuracy = 81.86%
  Batch 5: Loss = 0.1269, Accuracy = 82.06%
  Batch 10: Loss = 0.1971, Accuracy = 82.33%
  Batch 15: Loss = 0.0928, Accuracy = 82.43%
  Batch 20: Loss = 0.1057, Accuracy = 82.69%
Training on dataloader 22/38
  Batch 0: Loss = 0.3616, Accuracy = 82.91%
  Batch 5: Loss = 0.1252, Accuracy = 83.11%
  Batch 10: Loss = 0.3459, Accuracy = 83.26%
Training on dataloader 23/38
  Batch 0: Loss = 0.3767, Accuracy = 83.33%
  Batch 5: Loss = 0.1631, Accuracy = 83.32%
  Batch 10: Loss = 0.1182, Accuracy = 83.43%
Training on dataloader 24/38
  Batch 0: Loss = 0.5981, Accuracy = 83.41%
  Batch 5: Loss = 0.4104, Accuracy = 83.28%
  Batch 10: Loss = 0.5224, Accuracy = 83.23%
Training on dataloader 25/38
  Batch 0: Loss = 0.2815, Accuracy = 83.26%
  Batch 5: Loss = 0.2538, Accuracy = 83.14%
  Batch 10: Loss = 0.5727, Accuracy = 82.98%
Training on dataloader 26/38
  Batch 0: Loss = 0.0939, Accuracy = 83.03%
  Batch 5: Loss = 0.1492, Accuracy = 83.17%
  Batch 10: Loss = 0.1098, Accuracy = 83.30%
Training on dataloader 27/38
  Batch 0: Loss = 0.1822, Accuracy = 83.35%
  Batch 5: Loss = 0.1153, Accuracy = 83.51%
  Batch 10: Loss = 0.1530, Accuracy = 83.57%
  Batch 15: Loss = 0.5406, Accuracy = 83.72%
  Batch 20: Loss = 0.2752, Accuracy = 83.88%
Training on dataloader 28/38
  Batch 0: Loss = 0.2724, Accuracy = 83.92%
  Batch 5: Loss = 0.5580, Accuracy = 83.97%
  Batch 10: Loss = 0.1179, Accuracy = 84.08%
Training on dataloader 29/38
  Batch 0: Loss = 0.8750, Accuracy = 83.96%
  Batch 5: Loss = 1.1526, Accuracy = 83.65%
  Batch 10: Loss = 0.9784, Accuracy = 83.58%
Training on dataloader 30/38
  Batch 0: Loss = 0.3109, Accuracy = 83.59%
  Batch 5: Loss = 1.1274, Accuracy = 83.43%
  Batch 10: Loss = 0.1455, Accuracy = 83.45%
Error in batch 12 of dataloader 29: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 31/38
  Batch 0: Loss = 0.4485, Accuracy = 83.43%
  Batch 5: Loss = 0.1034, Accuracy = 83.57%
  Batch 10: Loss = 0.1113, Accuracy = 83.71%
  Batch 15: Loss = 0.2257, Accuracy = 83.84%
  Batch 20: Loss = 0.1648, Accuracy = 83.94%
Training on dataloader 32/38
  Batch 0: Loss = 0.0930, Accuracy = 84.08%
  Batch 5: Loss = 0.1667, Accuracy = 84.23%
  Batch 10: Loss = 0.0911, Accuracy = 84.33%
  Batch 15: Loss = 0.0912, Accuracy = 84.42%
  Batch 20: Loss = 0.4698, Accuracy = 84.53%
Training on dataloader 33/38
  Batch 0: Loss = 0.0812, Accuracy = 84.60%
  Batch 5: Loss = 0.0874, Accuracy = 84.74%
  Batch 10: Loss = 0.0907, Accuracy = 84.85%
  Batch 15: Loss = 0.0872, Accuracy = 84.96%
  Batch 20: Loss = 0.0736, Accuracy = 85.09%
Error in batch 22 of dataloader 32: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 34/38
  Batch 0: Loss = 0.3869, Accuracy = 85.13%
  Batch 5: Loss = 0.7608, Accuracy = 85.15%
  Batch 10: Loss = 0.4935, Accuracy = 85.20%
Training on dataloader 35/38
  Batch 0: Loss = 0.1306, Accuracy = 85.18%
  Batch 5: Loss = 0.2703, Accuracy = 85.23%
  Batch 10: Loss = 0.3500, Accuracy = 85.15%
Training on dataloader 36/38
  Batch 0: Loss = 0.1895, Accuracy = 85.17%
  Batch 5: Loss = 0.4635, Accuracy = 85.27%
  Batch 10: Loss = 0.0871, Accuracy = 85.39%
  Batch 15: Loss = 0.3025, Accuracy = 85.46%
  Batch 20: Loss = 0.2373, Accuracy = 85.60%
Training on dataloader 37/38
  Batch 0: Loss = 0.3433, Accuracy = 85.69%
  Batch 5: Loss = 0.0654, Accuracy = 85.82%
  Batch 10: Loss = 0.1806, Accuracy = 85.88%
  Batch 15: Loss = 0.1002, Accuracy = 86.01%
  Batch 20: Loss = 0.0770, Accuracy = 86.14%
Training on dataloader 38/38
  Batch 0: Loss = 1.2425, Accuracy = 86.14%
  Batch 5: Loss = 0.5480, Accuracy = 86.17%
  Batch 10: Loss = 0.7387, Accuracy = 86.07%

=== TRAINING EPOCH SUMMARY ===
Average Loss: 0.3908
Accuracy: 86.05%
Total Samples: 4488
==============================
Evaluating on dataloader 1/3
  Batch 0: Loss = 0.1230, Accuracy = 100.00%
  Batch 5: Loss = 0.0864, Accuracy = 97.92%
  Batch 10: Loss = 0.1492, Accuracy = 98.86%
  Batch 15: Loss = 0.0318, Accuracy = 99.22%
  Batch 20: Loss = 0.0234, Accuracy = 99.40%
Evaluating on dataloader 2/3
  Batch 0: Loss = 0.2621, Accuracy = 98.94%
  Batch 5: Loss = 0.0750, Accuracy = 98.69%
  Batch 10: Loss = 0.0601, Accuracy = 98.88%
  Batch 15: Loss = 0.3132, Accuracy = 98.38%
  Batch 20: Loss = 0.6446, Accuracy = 96.85%
  Batch 25: Loss = 0.0285, Accuracy = 96.63%
Evaluating on dataloader 3/3
  Batch 0: Loss = 0.0871, Accuracy = 96.70%
  Batch 5: Loss = 0.4093, Accuracy = 96.08%
  Batch 10: Loss = 0.4220, Accuracy = 95.99%

=== VALIDATION EPOCH SUMMARY ===
Average Loss: 0.1495
Accuracy: 95.87%
Total Samples: 484
===================================
New best validation accuracy: 95.87% - Models saved!

==================================================
EPOCH 8/20
==================================================
Training on dataloader 1/38
  Batch 0: Loss = 0.0996, Accuracy = 100.00%
  Batch 5: Loss = 0.1259, Accuracy = 89.58%
  Batch 10: Loss = 0.1476, Accuracy = 82.95%
Training on dataloader 2/38
  Batch 0: Loss = 0.4716, Accuracy = 81.37%
  Batch 5: Loss = 1.0821, Accuracy = 80.28%
  Batch 10: Loss = 0.1592, Accuracy = 81.87%
Training on dataloader 3/38
  Batch 0: Loss = 0.2172, Accuracy = 80.83%
  Batch 5: Loss = 0.8300, Accuracy = 81.55%
  Batch 10: Loss = 0.4185, Accuracy = 82.05%
Training on dataloader 4/38
  Batch 0: Loss = 1.2656, Accuracy = 82.01%
  Batch 5: Loss = 0.1433, Accuracy = 82.98%
  Batch 10: Loss = 0.6594, Accuracy = 82.93%
Training on dataloader 5/38
  Batch 0: Loss = 0.8213, Accuracy = 83.12%
  Batch 5: Loss = 0.3549, Accuracy = 82.59%
  Batch 10: Loss = 0.8633, Accuracy = 80.86%
Training on dataloader 6/38
  Batch 0: Loss = 0.5153, Accuracy = 80.33%
  Batch 5: Loss = 0.3493, Accuracy = 80.50%
  Batch 10: Loss = 0.1587, Accuracy = 79.40%
Training on dataloader 7/38
  Batch 0: Loss = 0.1807, Accuracy = 79.62%
  Batch 5: Loss = 0.3275, Accuracy = 79.16%
  Batch 10: Loss = 0.7188, Accuracy = 78.15%
Training on dataloader 8/38
  Batch 0: Loss = 0.8023, Accuracy = 78.12%
  Batch 5: Loss = 0.2621, Accuracy = 78.37%
  Batch 10: Loss = 0.3281, Accuracy = 78.86%
Training on dataloader 9/38
  Batch 0: Loss = 0.6250, Accuracy = 78.65%
  Batch 5: Loss = 0.5902, Accuracy = 78.96%
  Batch 10: Loss = 0.4238, Accuracy = 78.89%
Training on dataloader 10/38
  Batch 0: Loss = 0.1661, Accuracy = 79.28%
  Batch 5: Loss = 0.6853, Accuracy = 79.54%
  Batch 10: Loss = 0.7877, Accuracy = 79.45%
Training on dataloader 11/38
  Batch 0: Loss = 0.1667, Accuracy = 79.69%
  Batch 5: Loss = 0.6346, Accuracy = 79.20%
  Batch 10: Loss = 0.6452, Accuracy = 78.94%
Training on dataloader 12/38
  Batch 0: Loss = 0.4092, Accuracy = 78.98%
  Batch 5: Loss = 0.2039, Accuracy = 79.56%
  Batch 10: Loss = 0.1747, Accuracy = 80.28%
Training on dataloader 13/38
  Batch 0: Loss = 0.5528, Accuracy = 80.35%
  Batch 5: Loss = 0.1907, Accuracy = 80.50%
  Batch 10: Loss = 1.0262, Accuracy = 80.57%
Training on dataloader 14/38
  Batch 0: Loss = 0.1425, Accuracy = 80.79%
  Batch 5: Loss = 0.2875, Accuracy = 81.15%
  Batch 10: Loss = 0.1290, Accuracy = 81.50%
Training on dataloader 15/38
  Batch 0: Loss = 0.8399, Accuracy = 81.27%
  Batch 5: Loss = 0.3853, Accuracy = 81.38%
  Batch 10: Loss = 0.1476, Accuracy = 81.90%
  Batch 15: Loss = 0.3815, Accuracy = 82.19%
  Batch 20: Loss = 0.2604, Accuracy = 82.53%
  Batch 25: Loss = 0.0997, Accuracy = 82.73%
  Batch 30: Loss = 0.1330, Accuracy = 83.06%
Training on dataloader 16/38
  Batch 0: Loss = 0.4511, Accuracy = 83.02%
  Batch 5: Loss = 1.3037, Accuracy = 82.70%
  Batch 10: Loss = 0.9109, Accuracy = 82.51%
Training on dataloader 17/38
  Batch 0: Loss = 0.7680, Accuracy = 82.52%
  Batch 5: Loss = 0.2122, Accuracy = 82.81%
  Batch 10: Loss = 0.2640, Accuracy = 83.09%
  Batch 15: Loss = 0.1309, Accuracy = 83.46%
  Batch 20: Loss = 0.1272, Accuracy = 83.77%
Training on dataloader 18/38
  Batch 0: Loss = 0.3124, Accuracy = 83.92%
  Batch 5: Loss = 0.2180, Accuracy = 83.95%
  Batch 10: Loss = 1.0834, Accuracy = 83.50%
Training on dataloader 19/38
  Batch 0: Loss = 0.0970, Accuracy = 83.57%
  Batch 5: Loss = 0.1480, Accuracy = 83.55%
  Batch 10: Loss = 0.5480, Accuracy = 83.58%
Training on dataloader 20/38
  Batch 0: Loss = 0.4321, Accuracy = 83.53%
  Batch 5: Loss = 0.3013, Accuracy = 83.70%
  Batch 10: Loss = 0.3533, Accuracy = 83.72%
Training on dataloader 21/38
  Batch 0: Loss = 0.1166, Accuracy = 83.77%
  Batch 5: Loss = 0.1347, Accuracy = 83.93%
  Batch 10: Loss = 0.1034, Accuracy = 84.21%
  Batch 15: Loss = 0.0998, Accuracy = 84.45%
  Batch 20: Loss = 0.1249, Accuracy = 84.72%
Training on dataloader 22/38
  Batch 0: Loss = 0.3571, Accuracy = 84.74%
  Batch 5: Loss = 0.0833, Accuracy = 84.95%
  Batch 10: Loss = 0.1920, Accuracy = 85.20%
Training on dataloader 23/38
  Batch 0: Loss = 1.2386, Accuracy = 85.13%
  Batch 5: Loss = 0.9753, Accuracy = 85.13%
  Batch 10: Loss = 0.2195, Accuracy = 85.17%
Training on dataloader 24/38
  Batch 0: Loss = 0.2668, Accuracy = 85.14%
  Batch 5: Loss = 0.6332, Accuracy = 84.95%
  Batch 10: Loss = 0.7633, Accuracy = 84.68%
Training on dataloader 25/38
  Batch 0: Loss = 0.4364, Accuracy = 84.67%
  Batch 5: Loss = 0.4258, Accuracy = 84.71%
  Batch 10: Loss = 1.0214, Accuracy = 84.60%
Training on dataloader 26/38
  Batch 0: Loss = 0.6435, Accuracy = 84.57%
  Batch 5: Loss = 0.3936, Accuracy = 84.65%
  Batch 10: Loss = 0.2079, Accuracy = 84.73%
Training on dataloader 27/38
  Batch 0: Loss = 0.1307, Accuracy = 84.80%
  Batch 5: Loss = 0.1031, Accuracy = 84.98%
  Batch 10: Loss = 0.6521, Accuracy = 85.02%
  Batch 15: Loss = 0.0917, Accuracy = 85.15%
  Batch 20: Loss = 0.2340, Accuracy = 85.28%
Training on dataloader 28/38
  Batch 0: Loss = 0.0807, Accuracy = 85.36%
  Batch 5: Loss = 0.3724, Accuracy = 85.48%
  Batch 10: Loss = 0.1149, Accuracy = 85.51%
Training on dataloader 29/38
  Batch 0: Loss = 0.3732, Accuracy = 85.51%
  Batch 5: Loss = 0.0801, Accuracy = 85.47%
  Batch 10: Loss = 1.3542, Accuracy = 85.25%
Training on dataloader 30/38
  Batch 0: Loss = 0.3131, Accuracy = 85.23%
  Batch 5: Loss = 0.3460, Accuracy = 85.22%
  Batch 10: Loss = 0.3579, Accuracy = 85.25%
Error in batch 12 of dataloader 29: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 31/38
  Batch 0: Loss = 0.2075, Accuracy = 85.17%
  Batch 5: Loss = 0.1418, Accuracy = 85.29%
  Batch 10: Loss = 0.0906, Accuracy = 85.43%
  Batch 15: Loss = 0.1336, Accuracy = 85.58%
  Batch 20: Loss = 1.0778, Accuracy = 85.60%
Training on dataloader 32/38
  Batch 0: Loss = 0.2269, Accuracy = 85.64%
  Batch 5: Loss = 0.5559, Accuracy = 85.69%
  Batch 10: Loss = 0.1068, Accuracy = 85.85%
  Batch 15: Loss = 0.2078, Accuracy = 86.00%
  Batch 20: Loss = 0.0787, Accuracy = 86.16%
Training on dataloader 33/38
  Batch 0: Loss = 0.0826, Accuracy = 86.16%
  Batch 5: Loss = 0.2253, Accuracy = 86.29%
  Batch 10: Loss = 0.4264, Accuracy = 86.38%
  Batch 15: Loss = 0.0912, Accuracy = 86.50%
  Batch 20: Loss = 0.0613, Accuracy = 86.64%
Error in batch 22 of dataloader 32: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 34/38
  Batch 0: Loss = 0.5708, Accuracy = 86.67%
  Batch 5: Loss = 0.3261, Accuracy = 86.65%
  Batch 10: Loss = 0.1797, Accuracy = 86.69%
Training on dataloader 35/38
  Batch 0: Loss = 0.5174, Accuracy = 86.71%
  Batch 5: Loss = 0.0886, Accuracy = 86.74%
  Batch 10: Loss = 0.4380, Accuracy = 86.75%
Training on dataloader 36/38
  Batch 0: Loss = 0.0739, Accuracy = 86.74%
  Batch 5: Loss = 0.2393, Accuracy = 86.82%
  Batch 10: Loss = 0.1022, Accuracy = 86.95%
  Batch 15: Loss = 0.1222, Accuracy = 87.08%
  Batch 20: Loss = 0.0763, Accuracy = 87.20%
Training on dataloader 37/38
  Batch 0: Loss = 0.1439, Accuracy = 87.30%
  Batch 5: Loss = 0.0589, Accuracy = 87.37%
  Batch 10: Loss = 0.0732, Accuracy = 87.49%
  Batch 15: Loss = 0.0728, Accuracy = 87.60%
  Batch 20: Loss = 0.0832, Accuracy = 87.72%
Training on dataloader 38/38
  Batch 0: Loss = 0.0856, Accuracy = 87.77%
  Batch 5: Loss = 0.8178, Accuracy = 87.77%
  Batch 10: Loss = 0.1254, Accuracy = 87.72%

=== TRAINING EPOCH SUMMARY ===
Average Loss: 0.3656
Accuracy: 87.72%
Total Samples: 4488
==============================
Evaluating on dataloader 1/3
  Batch 0: Loss = 0.0235, Accuracy = 100.00%
  Batch 5: Loss = 0.0211, Accuracy = 100.00%
  Batch 10: Loss = 0.0223, Accuracy = 100.00%
  Batch 15: Loss = 0.1909, Accuracy = 100.00%
  Batch 20: Loss = 0.1007, Accuracy = 100.00%
Evaluating on dataloader 2/3
  Batch 0: Loss = 0.0246, Accuracy = 100.00%
  Batch 5: Loss = 0.0239, Accuracy = 99.56%
  Batch 10: Loss = 0.0205, Accuracy = 99.63%
  Batch 15: Loss = 0.6102, Accuracy = 98.38%
  Batch 20: Loss = 1.1613, Accuracy = 94.84%
  Batch 25: Loss = 0.1334, Accuracy = 93.78%
Evaluating on dataloader 3/3
  Batch 0: Loss = 0.7631, Accuracy = 93.40%
  Batch 5: Loss = 0.5200, Accuracy = 92.86%
  Batch 10: Loss = 0.0358, Accuracy = 93.04%

=== VALIDATION EPOCH SUMMARY ===
Average Loss: 0.2439
Accuracy: 92.98%
Total Samples: 484
===================================
No improvement in validation accuracy. Patience: 1/5

==================================================
EPOCH 9/20
==================================================
Training on dataloader 1/38
  Batch 0: Loss = 0.3570, Accuracy = 87.50%
  Batch 5: Loss = 0.1535, Accuracy = 79.17%
  Batch 10: Loss = 0.4648, Accuracy = 80.68%
Training on dataloader 2/38
  Batch 0: Loss = 0.9661, Accuracy = 80.39%
  Batch 5: Loss = 1.3595, Accuracy = 79.58%
  Batch 10: Loss = 0.5715, Accuracy = 79.67%
Training on dataloader 3/38
  Batch 0: Loss = 0.2175, Accuracy = 80.31%
  Batch 5: Loss = 0.3567, Accuracy = 81.12%
  Batch 10: Loss = 0.2520, Accuracy = 82.05%
Training on dataloader 4/38
  Batch 0: Loss = 0.4880, Accuracy = 81.66%
  Batch 5: Loss = 0.1987, Accuracy = 82.98%
  Batch 10: Loss = 0.1968, Accuracy = 82.93%
Training on dataloader 5/38
  Batch 0: Loss = 0.6003, Accuracy = 83.38%
  Batch 5: Loss = 0.6042, Accuracy = 82.35%
  Batch 10: Loss = 0.1507, Accuracy = 82.15%
Training on dataloader 6/38
  Batch 0: Loss = 0.1513, Accuracy = 82.61%
  Batch 5: Loss = 0.3554, Accuracy = 81.84%
  Batch 10: Loss = 0.9644, Accuracy = 82.24%
Training on dataloader 7/38
  Batch 0: Loss = 1.3277, Accuracy = 81.87%
  Batch 5: Loss = 0.9252, Accuracy = 80.78%
  Batch 10: Loss = 0.3455, Accuracy = 81.49%
Training on dataloader 8/38
  Batch 0: Loss = 0.1158, Accuracy = 81.70%
  Batch 5: Loss = 0.2376, Accuracy = 81.74%
  Batch 10: Loss = 0.0969, Accuracy = 82.45%
Training on dataloader 9/38
  Batch 0: Loss = 0.3594, Accuracy = 82.29%
  Batch 5: Loss = 1.0627, Accuracy = 81.44%
  Batch 10: Loss = 0.5550, Accuracy = 81.13%
Training on dataloader 10/38
  Batch 0: Loss = 1.0291, Accuracy = 80.67%
  Batch 5: Loss = 0.4973, Accuracy = 80.97%
  Batch 10: Loss = 0.4665, Accuracy = 81.04%
Training on dataloader 11/38
  Batch 0: Loss = 0.7899, Accuracy = 81.04%
  Batch 5: Loss = 0.8947, Accuracy = 80.80%
  Batch 10: Loss = 0.6927, Accuracy = 80.19%
Training on dataloader 12/38
  Batch 0: Loss = 0.3218, Accuracy = 80.21%
  Batch 5: Loss = 0.1910, Accuracy = 80.66%
  Batch 10: Loss = 0.5642, Accuracy = 80.72%
Training on dataloader 13/38
  Batch 0: Loss = 0.1720, Accuracy = 80.87%
  Batch 5: Loss = 0.7929, Accuracy = 80.50%
  Batch 10: Loss = 0.5138, Accuracy = 80.57%
Training on dataloader 14/38
  Batch 0: Loss = 0.3318, Accuracy = 80.63%
  Batch 5: Loss = 0.3620, Accuracy = 80.84%
  Batch 10: Loss = 0.1823, Accuracy = 80.74%
Training on dataloader 15/38
  Batch 0: Loss = 0.2631, Accuracy = 80.67%
  Batch 5: Loss = 0.1428, Accuracy = 80.43%
  Batch 10: Loss = 0.2126, Accuracy = 80.63%
  Batch 15: Loss = 0.4292, Accuracy = 80.75%
  Batch 20: Loss = 0.2914, Accuracy = 81.20%
  Batch 25: Loss = 0.1217, Accuracy = 81.43%
  Batch 30: Loss = 0.6797, Accuracy = 81.47%
Training on dataloader 16/38
  Batch 0: Loss = 0.3059, Accuracy = 81.50%
  Batch 5: Loss = 0.8418, Accuracy = 81.34%
  Batch 10: Loss = 0.9118, Accuracy = 80.95%
Training on dataloader 17/38
  Batch 0: Loss = 0.3418, Accuracy = 80.86%
  Batch 5: Loss = 0.2281, Accuracy = 81.01%
  Batch 10: Loss = 0.4405, Accuracy = 81.21%
  Batch 15: Loss = 0.4772, Accuracy = 81.30%
  Batch 20: Loss = 0.7144, Accuracy = 81.43%
Training on dataloader 18/38
  Batch 0: Loss = 0.4649, Accuracy = 81.56%
  Batch 5: Loss = 0.3635, Accuracy = 81.58%
  Batch 10: Loss = 0.2778, Accuracy = 81.76%
Training on dataloader 19/38
  Batch 0: Loss = 0.1083, Accuracy = 81.89%
  Batch 5: Loss = 0.4062, Accuracy = 81.95%
  Batch 10: Loss = 0.5116, Accuracy = 82.06%
Training on dataloader 20/38
  Batch 0: Loss = 0.4900, Accuracy = 82.17%
  Batch 5: Loss = 0.1700, Accuracy = 82.32%
  Batch 10: Loss = 0.4286, Accuracy = 82.18%
Training on dataloader 21/38
  Batch 0: Loss = 0.1625, Accuracy = 82.28%
  Batch 5: Loss = 0.2202, Accuracy = 82.56%
  Batch 10: Loss = 0.1277, Accuracy = 82.87%
  Batch 15: Loss = 0.0992, Accuracy = 83.13%
  Batch 20: Loss = 0.1023, Accuracy = 83.25%
Training on dataloader 22/38
  Batch 0: Loss = 0.6530, Accuracy = 83.42%
  Batch 5: Loss = 0.1069, Accuracy = 83.57%
  Batch 10: Loss = 0.1105, Accuracy = 83.72%
Training on dataloader 23/38
  Batch 0: Loss = 0.0889, Accuracy = 83.82%
  Batch 5: Loss = 0.7778, Accuracy = 83.92%
  Batch 10: Loss = 0.3289, Accuracy = 83.94%
Training on dataloader 24/38
  Batch 0: Loss = 0.8297, Accuracy = 83.81%
  Batch 5: Loss = 0.6018, Accuracy = 83.78%
  Batch 10: Loss = 0.5181, Accuracy = 83.73%
Training on dataloader 25/38
  Batch 0: Loss = 0.1184, Accuracy = 83.80%
  Batch 5: Loss = 0.1413, Accuracy = 83.93%
  Batch 10: Loss = 0.1897, Accuracy = 83.94%
Training on dataloader 26/38
  Batch 0: Loss = 0.2488, Accuracy = 83.95%
  Batch 5: Loss = 0.0929, Accuracy = 84.04%
  Batch 10: Loss = 0.3479, Accuracy = 83.98%
Training on dataloader 27/38
  Batch 0: Loss = 0.1988, Accuracy = 84.02%
  Batch 5: Loss = 0.0986, Accuracy = 84.11%
  Batch 10: Loss = 0.5090, Accuracy = 84.05%
  Batch 15: Loss = 0.5743, Accuracy = 84.20%
  Batch 20: Loss = 0.1078, Accuracy = 84.31%
Training on dataloader 28/38
  Batch 0: Loss = 0.1983, Accuracy = 84.39%
  Batch 5: Loss = 0.3115, Accuracy = 84.40%
  Batch 10: Loss = 0.2681, Accuracy = 84.41%
Training on dataloader 29/38
  Batch 0: Loss = 0.2679, Accuracy = 84.38%
  Batch 5: Loss = 0.4230, Accuracy = 84.32%
  Batch 10: Loss = 0.3456, Accuracy = 84.30%
Training on dataloader 30/38
  Batch 0: Loss = 0.4807, Accuracy = 84.22%
  Batch 5: Loss = 0.3451, Accuracy = 84.29%
  Batch 10: Loss = 1.0503, Accuracy = 84.00%
Error in batch 12 of dataloader 29: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 31/38
  Batch 0: Loss = 0.3795, Accuracy = 84.01%
  Batch 5: Loss = 0.1357, Accuracy = 84.12%
  Batch 10: Loss = 0.1232, Accuracy = 84.16%
  Batch 15: Loss = 0.2686, Accuracy = 84.25%
  Batch 20: Loss = 0.1646, Accuracy = 84.44%
Training on dataloader 32/38
  Batch 0: Loss = 0.0962, Accuracy = 84.51%
  Batch 5: Loss = 0.2412, Accuracy = 84.66%
  Batch 10: Loss = 0.6972, Accuracy = 84.81%
  Batch 15: Loss = 0.0863, Accuracy = 84.78%
  Batch 20: Loss = 0.0846, Accuracy = 84.92%
Training on dataloader 33/38
  Batch 0: Loss = 0.1916, Accuracy = 85.02%
  Batch 5: Loss = 0.1101, Accuracy = 85.18%
  Batch 10: Loss = 0.3572, Accuracy = 85.31%
  Batch 15: Loss = 0.0728, Accuracy = 85.46%
  Batch 20: Loss = 0.0772, Accuracy = 85.62%
Error in batch 22 of dataloader 32: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 34/38
  Batch 0: Loss = 0.0761, Accuracy = 85.65%
  Batch 5: Loss = 0.0750, Accuracy = 85.70%
  Batch 10: Loss = 0.0652, Accuracy = 85.77%
Training on dataloader 35/38
  Batch 0: Loss = 0.5453, Accuracy = 85.74%
  Batch 5: Loss = 0.3227, Accuracy = 85.78%
  Batch 10: Loss = 0.4305, Accuracy = 85.80%
Training on dataloader 36/38
  Batch 0: Loss = 0.0762, Accuracy = 85.80%
  Batch 5: Loss = 1.4685, Accuracy = 85.86%
  Batch 10: Loss = 0.0749, Accuracy = 86.00%
  Batch 15: Loss = 0.1896, Accuracy = 86.09%
  Batch 20: Loss = 0.1021, Accuracy = 86.22%
Training on dataloader 37/38
  Batch 0: Loss = 0.0852, Accuracy = 86.35%
  Batch 5: Loss = 0.0941, Accuracy = 86.46%
  Batch 10: Loss = 0.0657, Accuracy = 86.56%
  Batch 15: Loss = 0.0539, Accuracy = 86.68%
  Batch 20: Loss = 0.0801, Accuracy = 86.78%
Training on dataloader 38/38
  Batch 0: Loss = 0.6632, Accuracy = 86.77%
  Batch 5: Loss = 0.5937, Accuracy = 86.76%
  Batch 10: Loss = 1.4762, Accuracy = 86.67%

=== TRAINING EPOCH SUMMARY ===
Average Loss: 0.3812
Accuracy: 86.68%
Total Samples: 4488
==============================
Evaluating on dataloader 1/3
  Batch 0: Loss = 0.0420, Accuracy = 100.00%
  Batch 5: Loss = 0.0351, Accuracy = 100.00%
  Batch 10: Loss = 0.0358, Accuracy = 100.00%
  Batch 15: Loss = 0.0871, Accuracy = 100.00%
  Batch 20: Loss = 0.0520, Accuracy = 100.00%
Evaluating on dataloader 2/3
  Batch 0: Loss = 0.0477, Accuracy = 100.00%
  Batch 5: Loss = 0.0464, Accuracy = 99.56%
  Batch 10: Loss = 0.0353, Accuracy = 99.63%
  Batch 15: Loss = 0.6198, Accuracy = 98.38%
  Batch 20: Loss = 1.1063, Accuracy = 94.56%
  Batch 25: Loss = 0.0965, Accuracy = 92.75%
Evaluating on dataloader 3/3
  Batch 0: Loss = 0.4260, Accuracy = 92.64%
  Batch 5: Loss = 0.4666, Accuracy = 92.63%
  Batch 10: Loss = 0.2285, Accuracy = 92.83%

=== VALIDATION EPOCH SUMMARY ===
Average Loss: 0.2114
Accuracy: 92.98%
Total Samples: 484
===================================
No improvement in validation accuracy. Patience: 2/5

==================================================
EPOCH 10/20
==================================================
Training on dataloader 1/38
  Batch 0: Loss = 0.3510, Accuracy = 87.50%
  Batch 5: Loss = 0.4187, Accuracy = 85.42%
  Batch 10: Loss = 0.4749, Accuracy = 85.23%
Training on dataloader 2/38
  Batch 0: Loss = 0.7808, Accuracy = 85.29%
  Batch 5: Loss = 0.4711, Accuracy = 83.10%
  Batch 10: Loss = 0.9624, Accuracy = 81.32%
Training on dataloader 3/38
  Batch 0: Loss = 1.2269, Accuracy = 80.31%
  Batch 5: Loss = 0.9578, Accuracy = 77.68%
  Batch 10: Loss = 1.0421, Accuracy = 79.12%
Training on dataloader 4/38
  Batch 0: Loss = 0.9837, Accuracy = 78.20%
  Batch 5: Loss = 0.2043, Accuracy = 80.24%
  Batch 10: Loss = 0.1774, Accuracy = 82.11%
Training on dataloader 5/38
  Batch 0: Loss = 0.0975, Accuracy = 82.34%
  Batch 5: Loss = 0.4079, Accuracy = 80.94%
  Batch 10: Loss = 0.6049, Accuracy = 80.22%
Training on dataloader 6/38
  Batch 0: Loss = 0.3509, Accuracy = 80.33%
  Batch 5: Loss = 0.1030, Accuracy = 80.69%
  Batch 10: Loss = 0.5931, Accuracy = 81.53%
Training on dataloader 7/38
  Batch 0: Loss = 1.1784, Accuracy = 81.35%
  Batch 5: Loss = 0.4448, Accuracy = 81.26%
  Batch 10: Loss = 1.1736, Accuracy = 81.03%
Training on dataloader 8/38
  Batch 0: Loss = 0.1632, Accuracy = 81.25%
  Batch 5: Loss = 0.7579, Accuracy = 81.60%
  Batch 10: Loss = 0.2045, Accuracy = 82.18%
Training on dataloader 9/38
  Batch 0: Loss = 1.2625, Accuracy = 81.90%
  Batch 5: Loss = 0.1065, Accuracy = 82.30%
  Batch 10: Loss = 0.7541, Accuracy = 82.43%
Training on dataloader 10/38
  Batch 0: Loss = 0.3671, Accuracy = 82.29%
  Batch 5: Loss = 0.1073, Accuracy = 82.63%
  Batch 10: Loss = 0.1841, Accuracy = 82.84%
Training on dataloader 11/38
  Batch 0: Loss = 0.7040, Accuracy = 82.71%
  Batch 5: Loss = 0.9100, Accuracy = 82.30%
  Batch 10: Loss = 0.5548, Accuracy = 82.12%
Training on dataloader 12/38
  Batch 0: Loss = 0.1663, Accuracy = 82.10%
  Batch 5: Loss = 0.1441, Accuracy = 82.57%
  Batch 10: Loss = 0.1194, Accuracy = 82.92%
Training on dataloader 13/38
  Batch 0: Loss = 0.8021, Accuracy = 82.70%
  Batch 5: Loss = 0.1544, Accuracy = 82.61%
  Batch 10: Loss = 0.2603, Accuracy = 82.68%
Training on dataloader 14/38
  Batch 0: Loss = 0.2175, Accuracy = 82.72%
  Batch 5: Loss = 0.2791, Accuracy = 83.02%
  Batch 10: Loss = 0.2059, Accuracy = 83.23%
Training on dataloader 15/38
  Batch 0: Loss = 0.1745, Accuracy = 83.43%
  Batch 5: Loss = 0.1163, Accuracy = 83.62%
  Batch 10: Loss = 0.3210, Accuracy = 83.73%
  Batch 15: Loss = 0.2717, Accuracy = 83.90%
  Batch 20: Loss = 0.2237, Accuracy = 84.20%
  Batch 25: Loss = 0.1813, Accuracy = 84.35%
  Batch 30: Loss = 1.4515, Accuracy = 84.33%
Training on dataloader 16/38
  Batch 0: Loss = 1.5129, Accuracy = 84.15%
  Batch 5: Loss = 0.5923, Accuracy = 83.62%
  Batch 10: Loss = 0.2412, Accuracy = 83.53%
Training on dataloader 17/38
  Batch 0: Loss = 0.1154, Accuracy = 83.53%
  Batch 5: Loss = 0.5311, Accuracy = 83.57%
  Batch 10: Loss = 0.1197, Accuracy = 83.94%
  Batch 15: Loss = 0.6692, Accuracy = 84.13%
  Batch 20: Loss = 0.1116, Accuracy = 84.47%
Training on dataloader 18/38
  Batch 0: Loss = 0.5332, Accuracy = 84.62%
  Batch 5: Loss = 0.3828, Accuracy = 84.37%
  Batch 10: Loss = 0.1333, Accuracy = 84.48%
Training on dataloader 19/38
  Batch 0: Loss = 0.1261, Accuracy = 84.54%
  Batch 5: Loss = 0.2683, Accuracy = 84.45%
  Batch 10: Loss = 0.3096, Accuracy = 84.51%
Training on dataloader 20/38
  Batch 0: Loss = 0.6969, Accuracy = 84.45%
  Batch 5: Loss = 0.7469, Accuracy = 84.37%
  Batch 10: Loss = 0.5800, Accuracy = 84.33%
Training on dataloader 21/38
  Batch 0: Loss = 0.1341, Accuracy = 84.37%
  Batch 5: Loss = 0.1558, Accuracy = 84.61%
  Batch 10: Loss = 0.2103, Accuracy = 84.84%
  Batch 15: Loss = 0.3950, Accuracy = 84.89%
  Batch 20: Loss = 0.1428, Accuracy = 85.15%
Training on dataloader 22/38
  Batch 0: Loss = 0.1033, Accuracy = 85.33%
  Batch 5: Loss = 0.4760, Accuracy = 85.37%
  Batch 10: Loss = 0.1493, Accuracy = 85.44%
Training on dataloader 23/38
  Batch 0: Loss = 0.0851, Accuracy = 85.46%
  Batch 5: Loss = 0.5843, Accuracy = 85.45%
  Batch 10: Loss = 1.3290, Accuracy = 85.28%
Training on dataloader 24/38
  Batch 0: Loss = 0.5353, Accuracy = 85.34%
  Batch 5: Loss = 0.7809, Accuracy = 85.18%
  Batch 10: Loss = 0.5307, Accuracy = 85.14%
Training on dataloader 25/38
  Batch 0: Loss = 0.1764, Accuracy = 85.12%
  Batch 5: Loss = 0.2040, Accuracy = 85.08%
  Batch 10: Loss = 0.7049, Accuracy = 84.75%
Training on dataloader 26/38
  Batch 0: Loss = 0.1621, Accuracy = 84.83%
  Batch 5: Loss = 0.5979, Accuracy = 84.83%
  Batch 10: Loss = 0.3733, Accuracy = 84.87%
Training on dataloader 27/38
  Batch 0: Loss = 0.1643, Accuracy = 84.91%
  Batch 5: Loss = 0.1354, Accuracy = 85.02%
  Batch 10: Loss = 0.1154, Accuracy = 85.08%
  Batch 15: Loss = 0.3613, Accuracy = 85.19%
  Batch 20: Loss = 0.1317, Accuracy = 85.35%
Training on dataloader 28/38
  Batch 0: Loss = 0.2168, Accuracy = 85.42%
  Batch 5: Loss = 0.1115, Accuracy = 85.52%
  Batch 10: Loss = 0.4984, Accuracy = 85.58%
Training on dataloader 29/38
  Batch 0: Loss = 0.1344, Accuracy = 85.61%
  Batch 5: Loss = 0.5829, Accuracy = 85.47%
  Batch 10: Loss = 0.4680, Accuracy = 85.21%
Training on dataloader 30/38
  Batch 0: Loss = 0.4451, Accuracy = 85.23%
  Batch 5: Loss = 0.3827, Accuracy = 85.07%
  Batch 10: Loss = 0.6059, Accuracy = 84.88%
Error in batch 12 of dataloader 29: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 31/38
  Batch 0: Loss = 0.1251, Accuracy = 84.90%
  Batch 5: Loss = 0.1772, Accuracy = 85.02%
  Batch 10: Loss = 0.7289, Accuracy = 84.99%
  Batch 15: Loss = 0.2620, Accuracy = 85.08%
  Batch 20: Loss = 0.8978, Accuracy = 85.16%
Training on dataloader 32/38
  Batch 0: Loss = 0.2472, Accuracy = 85.23%
  Batch 5: Loss = 0.2149, Accuracy = 85.23%
  Batch 10: Loss = 0.6430, Accuracy = 85.34%
  Batch 15: Loss = 0.1610, Accuracy = 85.45%
  Batch 20: Loss = 0.1010, Accuracy = 85.58%
Training on dataloader 33/38
  Batch 0: Loss = 0.1099, Accuracy = 85.67%
  Batch 5: Loss = 0.1038, Accuracy = 85.77%
  Batch 10: Loss = 0.0789, Accuracy = 85.90%
  Batch 15: Loss = 0.0818, Accuracy = 85.97%
  Batch 20: Loss = 0.0843, Accuracy = 86.06%
Error in batch 22 of dataloader 32: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 34/38
  Batch 0: Loss = 0.6494, Accuracy = 86.04%
  Batch 5: Loss = 0.1785, Accuracy = 86.06%
  Batch 10: Loss = 0.1736, Accuracy = 86.05%
Training on dataloader 35/38
  Batch 0: Loss = 1.0197, Accuracy = 85.99%
  Batch 5: Loss = 0.2585, Accuracy = 85.93%
  Batch 10: Loss = 0.7370, Accuracy = 85.92%
Training on dataloader 36/38
  Batch 0: Loss = 0.0825, Accuracy = 85.95%
  Batch 5: Loss = 0.5081, Accuracy = 86.06%
  Batch 10: Loss = 0.1098, Accuracy = 86.15%
  Batch 15: Loss = 0.1305, Accuracy = 86.26%
  Batch 20: Loss = 0.0799, Accuracy = 86.39%
Training on dataloader 37/38
  Batch 0: Loss = 0.1108, Accuracy = 86.52%
  Batch 5: Loss = 0.5460, Accuracy = 86.57%
  Batch 10: Loss = 0.0715, Accuracy = 86.67%
  Batch 15: Loss = 0.0628, Accuracy = 86.80%
  Batch 20: Loss = 0.2009, Accuracy = 86.89%
Training on dataloader 38/38
  Batch 0: Loss = 0.4716, Accuracy = 86.93%
  Batch 5: Loss = 0.9607, Accuracy = 86.89%
  Batch 10: Loss = 0.7974, Accuracy = 86.85%

=== TRAINING EPOCH SUMMARY ===
Average Loss: 0.3986
Accuracy: 86.85%
Total Samples: 4488
==============================
Evaluating on dataloader 1/3
  Batch 0: Loss = 0.0444, Accuracy = 100.00%
  Batch 5: Loss = 0.0301, Accuracy = 87.50%
  Batch 10: Loss = 0.2569, Accuracy = 89.77%
  Batch 15: Loss = 0.1676, Accuracy = 92.97%
  Batch 20: Loss = 0.1080, Accuracy = 94.64%
Evaluating on dataloader 2/3
  Batch 0: Loss = 0.3929, Accuracy = 94.71%
  Batch 5: Loss = 0.0407, Accuracy = 93.45%
  Batch 10: Loss = 0.3126, Accuracy = 91.82%
  Batch 15: Loss = 0.3284, Accuracy = 92.56%
  Batch 20: Loss = 0.5342, Accuracy = 92.84%
  Batch 25: Loss = 0.1358, Accuracy = 93.52%
Evaluating on dataloader 3/3
  Batch 0: Loss = 0.1795, Accuracy = 93.40%
  Batch 5: Loss = 0.5146, Accuracy = 93.09%
  Batch 10: Loss = 0.5185, Accuracy = 92.41%

=== VALIDATION EPOCH SUMMARY ===
Average Loss: 0.2482
Accuracy: 92.36%
Total Samples: 484
===================================
No improvement in validation accuracy. Patience: 3/5

==================================================
EPOCH 11/20
==================================================
Training on dataloader 1/38
  Batch 0: Loss = 0.1559, Accuracy = 100.00%
  Batch 5: Loss = 1.6127, Accuracy = 83.33%
  Batch 10: Loss = 0.0807, Accuracy = 86.36%
Training on dataloader 2/38
  Batch 0: Loss = 0.6404, Accuracy = 83.33%
  Batch 5: Loss = 0.2042, Accuracy = 85.21%
  Batch 10: Loss = 1.4075, Accuracy = 84.62%
Training on dataloader 3/38
  Batch 0: Loss = 0.0986, Accuracy = 85.49%
  Batch 5: Loss = 0.4605, Accuracy = 85.41%
  Batch 10: Loss = 1.0801, Accuracy = 84.98%
Training on dataloader 4/38
  Batch 0: Loss = 0.7212, Accuracy = 84.43%
  Batch 5: Loss = 0.2036, Accuracy = 83.89%
  Batch 10: Loss = 0.0891, Accuracy = 82.66%
Training on dataloader 5/38
  Batch 0: Loss = 0.2661, Accuracy = 83.12%
  Batch 5: Loss = 1.5983, Accuracy = 82.59%
  Batch 10: Loss = 0.1902, Accuracy = 81.94%
Training on dataloader 6/38
  Batch 0: Loss = 0.8395, Accuracy = 81.37%
  Batch 5: Loss = 0.1508, Accuracy = 81.64%
  Batch 10: Loss = 0.3076, Accuracy = 82.06%
Training on dataloader 7/38
  Batch 0: Loss = 0.5971, Accuracy = 82.04%
  Batch 5: Loss = 0.6970, Accuracy = 81.91%
  Batch 10: Loss = 0.9560, Accuracy = 81.34%
Training on dataloader 8/38
  Batch 0: Loss = 0.7024, Accuracy = 81.25%
  Batch 5: Loss = 0.4903, Accuracy = 81.46%
  Batch 10: Loss = 0.3180, Accuracy = 81.52%
Training on dataloader 9/38
  Batch 0: Loss = 0.5420, Accuracy = 81.25%
  Batch 5: Loss = 0.4485, Accuracy = 80.82%
  Batch 10: Loss = 0.8418, Accuracy = 80.66%
Training on dataloader 10/38
  Batch 0: Loss = 0.2144, Accuracy = 81.02%
  Batch 5: Loss = 0.5854, Accuracy = 81.08%
  Batch 10: Loss = 0.2418, Accuracy = 81.46%
Training on dataloader 11/38
  Batch 0: Loss = 0.7575, Accuracy = 81.25%
  Batch 5: Loss = 1.0010, Accuracy = 80.80%
  Batch 10: Loss = 0.6183, Accuracy = 80.96%
Training on dataloader 12/38
  Batch 0: Loss = 0.1274, Accuracy = 81.06%
  Batch 5: Loss = 0.1882, Accuracy = 81.48%
  Batch 10: Loss = 0.2287, Accuracy = 81.95%
Training on dataloader 13/38
  Batch 0: Loss = 0.4835, Accuracy = 82.09%
  Batch 5: Loss = 0.8478, Accuracy = 82.10%
  Batch 10: Loss = 0.3351, Accuracy = 82.03%
Training on dataloader 14/38
  Batch 0: Loss = 0.2482, Accuracy = 82.07%
  Batch 5: Loss = 0.1869, Accuracy = 82.17%
  Batch 10: Loss = 0.1622, Accuracy = 82.40%
Training on dataloader 15/38
  Batch 0: Loss = 0.2109, Accuracy = 82.54%
  Batch 5: Loss = 0.6204, Accuracy = 82.61%
  Batch 10: Loss = 0.3873, Accuracy = 82.82%
  Batch 15: Loss = 0.1147, Accuracy = 82.74%
  Batch 20: Loss = 0.2993, Accuracy = 83.07%
  Batch 25: Loss = 0.1659, Accuracy = 83.38%
  Batch 30: Loss = 0.1739, Accuracy = 83.25%
Training on dataloader 16/38
  Batch 0: Loss = 0.8459, Accuracy = 83.21%
  Batch 5: Loss = 1.1123, Accuracy = 82.82%
  Batch 10: Loss = 0.5937, Accuracy = 82.69%
Training on dataloader 17/38
  Batch 0: Loss = 0.1487, Accuracy = 82.70%
  Batch 5: Loss = 0.4071, Accuracy = 82.98%
  Batch 10: Loss = 0.2212, Accuracy = 83.20%
  Batch 15: Loss = 0.2029, Accuracy = 83.35%
  Batch 20: Loss = 0.1814, Accuracy = 83.71%
Training on dataloader 18/38
  Batch 0: Loss = 0.7184, Accuracy = 83.76%
  Batch 5: Loss = 0.2127, Accuracy = 83.79%
  Batch 10: Loss = 0.2655, Accuracy = 83.97%
Training on dataloader 19/38
  Batch 0: Loss = 0.8262, Accuracy = 83.93%
  Batch 5: Loss = 0.1062, Accuracy = 84.10%
  Batch 10: Loss = 0.4216, Accuracy = 84.02%
Training on dataloader 20/38
  Batch 0: Loss = 0.0984, Accuracy = 84.11%
  Batch 5: Loss = 0.9117, Accuracy = 84.03%
  Batch 10: Loss = 0.3892, Accuracy = 84.05%
Training on dataloader 21/38
  Batch 0: Loss = 0.1155, Accuracy = 84.14%
  Batch 5: Loss = 0.1289, Accuracy = 84.43%
  Batch 10: Loss = 0.1488, Accuracy = 84.70%
  Batch 15: Loss = 0.1569, Accuracy = 84.93%
  Batch 20: Loss = 0.0907, Accuracy = 85.19%
Training on dataloader 22/38
  Batch 0: Loss = 1.0580, Accuracy = 85.29%
  Batch 5: Loss = 0.0920, Accuracy = 85.45%
  Batch 10: Loss = 0.5869, Accuracy = 85.53%
Training on dataloader 23/38
  Batch 0: Loss = 0.6873, Accuracy = 85.46%
  Batch 5: Loss = 0.4675, Accuracy = 85.33%
  Batch 10: Loss = 0.4535, Accuracy = 85.32%
Training on dataloader 24/38
  Batch 0: Loss = 0.7951, Accuracy = 85.34%
  Batch 5: Loss = 0.8161, Accuracy = 85.22%
  Batch 10: Loss = 0.5218, Accuracy = 85.02%
Training on dataloader 25/38
  Batch 0: Loss = 0.5963, Accuracy = 84.97%
  Batch 5: Loss = 0.4562, Accuracy = 85.01%
  Batch 10: Loss = 0.2511, Accuracy = 85.01%
Training on dataloader 26/38
  Batch 0: Loss = 0.3564, Accuracy = 84.98%
  Batch 5: Loss = 0.8324, Accuracy = 85.01%
  Batch 10: Loss = 0.6009, Accuracy = 85.05%
Training on dataloader 27/38
  Batch 0: Loss = 0.1403, Accuracy = 85.12%
  Batch 5: Loss = 0.4163, Accuracy = 85.19%
  Batch 10: Loss = 0.0964, Accuracy = 85.36%
  Batch 15: Loss = 0.0957, Accuracy = 85.42%
  Batch 20: Loss = 0.0847, Accuracy = 85.62%
Training on dataloader 28/38
  Batch 0: Loss = 0.1311, Accuracy = 85.66%
  Batch 5: Loss = 0.4752, Accuracy = 85.68%
  Batch 10: Loss = 0.2370, Accuracy = 85.74%
Training on dataloader 29/38
  Batch 0: Loss = 0.6749, Accuracy = 85.74%
  Batch 5: Loss = 1.1203, Accuracy = 85.57%
  Batch 10: Loss = 1.0588, Accuracy = 85.50%
Training on dataloader 30/38
  Batch 0: Loss = 0.9271, Accuracy = 85.48%
  Batch 5: Loss = 0.1413, Accuracy = 85.38%
  Batch 10: Loss = 0.8687, Accuracy = 85.37%
Error in batch 12 of dataloader 29: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 31/38
  Batch 0: Loss = 0.5813, Accuracy = 85.35%
  Batch 5: Loss = 0.1315, Accuracy = 85.47%
  Batch 10: Loss = 0.1076, Accuracy = 85.55%
  Batch 15: Loss = 0.1100, Accuracy = 85.66%
  Batch 20: Loss = 0.0926, Accuracy = 85.83%
Training on dataloader 32/38
  Batch 0: Loss = 0.2197, Accuracy = 85.95%
  Batch 5: Loss = 0.0907, Accuracy = 86.11%
  Batch 10: Loss = 0.0907, Accuracy = 86.24%
  Batch 15: Loss = 0.1573, Accuracy = 86.34%
  Batch 20: Loss = 0.0744, Accuracy = 86.49%
Training on dataloader 33/38
  Batch 0: Loss = 0.0885, Accuracy = 86.49%
  Batch 5: Loss = 0.0607, Accuracy = 86.61%
  Batch 10: Loss = 0.0675, Accuracy = 86.73%
  Batch 15: Loss = 0.3040, Accuracy = 86.76%
  Batch 20: Loss = 0.0642, Accuracy = 86.80%
Error in batch 22 of dataloader 32: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 34/38
  Batch 0: Loss = 0.4108, Accuracy = 86.82%
  Batch 5: Loss = 0.7524, Accuracy = 86.86%
  Batch 10: Loss = 0.8076, Accuracy = 86.92%
Training on dataloader 35/38
  Batch 0: Loss = 0.5559, Accuracy = 86.94%
  Batch 5: Loss = 0.0745, Accuracy = 87.04%
  Batch 10: Loss = 0.9507, Accuracy = 87.02%
Training on dataloader 36/38
  Batch 0: Loss = 0.5220, Accuracy = 86.99%
  Batch 5: Loss = 0.0728, Accuracy = 87.09%
  Batch 10: Loss = 0.1383, Accuracy = 87.22%
  Batch 15: Loss = 0.0615, Accuracy = 87.34%
  Batch 20: Loss = 0.2470, Accuracy = 87.44%
Training on dataloader 37/38
  Batch 0: Loss = 0.0593, Accuracy = 87.54%
  Batch 5: Loss = 0.0581, Accuracy = 87.65%
  Batch 10: Loss = 0.0567, Accuracy = 87.77%
  Batch 15: Loss = 0.3852, Accuracy = 87.86%
  Batch 20: Loss = 0.0537, Accuracy = 87.90%
Training on dataloader 38/38
  Batch 0: Loss = 1.3818, Accuracy = 87.86%
  Batch 5: Loss = 0.0601, Accuracy = 87.66%
  Batch 10: Loss = 0.6302, Accuracy = 87.61%

=== TRAINING EPOCH SUMMARY ===
Average Loss: 0.3738
Accuracy: 87.61%
Total Samples: 4488
==============================
Evaluating on dataloader 1/3
  Batch 0: Loss = 0.0269, Accuracy = 100.00%
  Batch 5: Loss = 0.0237, Accuracy = 100.00%
  Batch 10: Loss = 0.0239, Accuracy = 100.00%
  Batch 15: Loss = 1.8872, Accuracy = 87.50%
  Batch 20: Loss = 0.8081, Accuracy = 79.76%
Evaluating on dataloader 2/3
  Batch 0: Loss = 0.0292, Accuracy = 78.31%
  Batch 5: Loss = 0.0290, Accuracy = 82.10%
  Batch 10: Loss = 0.0208, Accuracy = 84.76%
  Batch 15: Loss = 1.9938, Accuracy = 82.52%
  Batch 20: Loss = 3.1663, Accuracy = 74.21%
  Batch 25: Loss = 1.8977, Accuracy = 69.17%
Evaluating on dataloader 3/3
  Batch 0: Loss = 0.4603, Accuracy = 69.54%
  Batch 5: Loss = 0.5352, Accuracy = 71.20%
  Batch 10: Loss = 0.0712, Accuracy = 73.21%

=== VALIDATION EPOCH SUMMARY ===
Average Loss: 0.7878
Accuracy: 73.76%
Total Samples: 484
===================================
No improvement in validation accuracy. Patience: 4/5

==================================================
EPOCH 12/20
==================================================
Training on dataloader 1/38
  Batch 0: Loss = 0.9031, Accuracy = 75.00%
  Batch 5: Loss = 0.1250, Accuracy = 85.42%
  Batch 10: Loss = 0.5796, Accuracy = 86.36%
Training on dataloader 2/38
  Batch 0: Loss = 0.7249, Accuracy = 85.29%
  Batch 5: Loss = 0.4798, Accuracy = 82.39%
  Batch 10: Loss = 0.7664, Accuracy = 80.77%
Training on dataloader 3/38
  Batch 0: Loss = 1.1819, Accuracy = 79.79%
  Batch 5: Loss = 0.2685, Accuracy = 81.12%
  Batch 10: Loss = 0.1612, Accuracy = 82.42%
Training on dataloader 4/38
  Batch 0: Loss = 0.6778, Accuracy = 82.01%
  Batch 5: Loss = 0.1438, Accuracy = 83.89%
  Batch 10: Loss = 0.1321, Accuracy = 84.01%
Training on dataloader 5/38
  Batch 0: Loss = 0.8014, Accuracy = 83.64%
  Batch 5: Loss = 0.7691, Accuracy = 83.29%
  Batch 10: Loss = 0.2263, Accuracy = 84.09%
Training on dataloader 6/38
  Batch 0: Loss = 1.2357, Accuracy = 83.64%
  Batch 5: Loss = 0.4460, Accuracy = 83.75%
  Batch 10: Loss = 0.3213, Accuracy = 84.01%
Training on dataloader 7/38
  Batch 0: Loss = 0.3496, Accuracy = 83.77%
  Batch 5: Loss = 0.0967, Accuracy = 83.52%
  Batch 10: Loss = 0.1293, Accuracy = 83.16%
Training on dataloader 8/38
  Batch 0: Loss = 0.6370, Accuracy = 83.04%
  Batch 5: Loss = 0.7245, Accuracy = 82.16%
  Batch 10: Loss = 0.0837, Accuracy = 82.58%
Training on dataloader 9/38
  Batch 0: Loss = 0.0878, Accuracy = 82.94%
  Batch 5: Loss = 0.2376, Accuracy = 82.55%
  Batch 10: Loss = 0.1371, Accuracy = 82.55%
Training on dataloader 10/38
  Batch 0: Loss = 0.4649, Accuracy = 82.64%
  Batch 5: Loss = 0.3885, Accuracy = 82.85%
  Batch 10: Loss = 0.4975, Accuracy = 82.84%
Training on dataloader 11/38
  Batch 0: Loss = 0.9891, Accuracy = 82.71%
  Batch 5: Loss = 1.0205, Accuracy = 82.10%
  Batch 10: Loss = 0.9739, Accuracy = 81.63%
Training on dataloader 12/38
  Batch 0: Loss = 0.2211, Accuracy = 81.53%
  Batch 5: Loss = 0.5262, Accuracy = 81.75%
  Batch 10: Loss = 0.1068, Accuracy = 82.22%
Training on dataloader 13/38
  Batch 0: Loss = 0.4637, Accuracy = 82.26%
  Batch 5: Loss = 0.3459, Accuracy = 81.76%
  Batch 10: Loss = 0.2911, Accuracy = 82.03%
Training on dataloader 14/38
  Batch 0: Loss = 0.7891, Accuracy = 81.59%
  Batch 5: Loss = 0.1288, Accuracy = 82.17%
  Batch 10: Loss = 0.1073, Accuracy = 82.55%
Training on dataloader 15/38
  Batch 0: Loss = 0.1850, Accuracy = 82.61%
  Batch 5: Loss = 0.1205, Accuracy = 83.12%
  Batch 10: Loss = 0.1828, Accuracy = 83.45%
  Batch 15: Loss = 0.0947, Accuracy = 83.77%
  Batch 20: Loss = 0.2262, Accuracy = 83.93%
  Batch 25: Loss = 0.0898, Accuracy = 84.22%
  Batch 30: Loss = 0.1713, Accuracy = 84.58%
Training on dataloader 16/38
  Batch 0: Loss = 0.7473, Accuracy = 84.53%
  Batch 5: Loss = 0.4033, Accuracy = 84.24%
  Batch 10: Loss = 0.6331, Accuracy = 84.25%
Training on dataloader 17/38
  Batch 0: Loss = 0.4288, Accuracy = 84.30%
  Batch 5: Loss = 0.1942, Accuracy = 84.55%
  Batch 10: Loss = 0.0869, Accuracy = 84.62%
  Batch 15: Loss = 0.0894, Accuracy = 84.85%
  Batch 20: Loss = 0.0805, Accuracy = 85.18%
Training on dataloader 18/38
  Batch 0: Loss = 0.1994, Accuracy = 85.32%
  Batch 5: Loss = 0.3913, Accuracy = 85.47%
  Batch 10: Loss = 0.4251, Accuracy = 85.56%
Training on dataloader 19/38
  Batch 0: Loss = 0.7802, Accuracy = 85.56%
  Batch 5: Loss = 0.4200, Accuracy = 85.70%
  Batch 10: Loss = 0.4231, Accuracy = 85.88%
Training on dataloader 20/38
  Batch 0: Loss = 0.4039, Accuracy = 85.91%
  Batch 5: Loss = 0.1341, Accuracy = 86.13%
  Batch 10: Loss = 0.1819, Accuracy = 86.06%
Training on dataloader 21/38
  Batch 0: Loss = 0.3081, Accuracy = 86.09%
  Batch 5: Loss = 0.1051, Accuracy = 86.20%
  Batch 10: Loss = 0.0966, Accuracy = 86.45%
  Batch 15: Loss = 0.0655, Accuracy = 86.64%
  Batch 20: Loss = 0.0734, Accuracy = 86.83%
Training on dataloader 22/38
  Batch 0: Loss = 0.1561, Accuracy = 86.99%
  Batch 5: Loss = 0.0720, Accuracy = 87.08%
  Batch 10: Loss = 0.0574, Accuracy = 87.17%
Training on dataloader 23/38
  Batch 0: Loss = 0.1507, Accuracy = 87.25%
  Batch 5: Loss = 0.2108, Accuracy = 87.26%
  Batch 10: Loss = 0.2197, Accuracy = 87.18%
Training on dataloader 24/38
  Batch 0: Loss = 0.5873, Accuracy = 87.07%
  Batch 5: Loss = 0.6224, Accuracy = 86.92%
  Batch 10: Loss = 0.8107, Accuracy = 86.78%
Training on dataloader 25/38
  Batch 0: Loss = 0.3294, Accuracy = 86.72%
  Batch 5: Loss = 0.4882, Accuracy = 86.65%
  Batch 10: Loss = 0.3276, Accuracy = 86.70%
Training on dataloader 26/38
  Batch 0: Loss = 0.8785, Accuracy = 86.66%
  Batch 5: Loss = 0.1454, Accuracy = 86.71%
  Batch 10: Loss = 0.0827, Accuracy = 86.83%
Training on dataloader 27/38
  Batch 0: Loss = 0.1428, Accuracy = 86.86%
  Batch 5: Loss = 0.1746, Accuracy = 86.97%
  Batch 10: Loss = 0.0633, Accuracy = 87.15%
  Batch 15: Loss = 0.1338, Accuracy = 87.29%
  Batch 20: Loss = 0.1607, Accuracy = 87.43%
Training on dataloader 28/38
  Batch 0: Loss = 0.0800, Accuracy = 87.46%
  Batch 5: Loss = 0.3188, Accuracy = 87.49%
  Batch 10: Loss = 0.4297, Accuracy = 87.59%
Training on dataloader 29/38
  Batch 0: Loss = 0.5755, Accuracy = 87.58%
  Batch 5: Loss = 0.5997, Accuracy = 87.48%
  Batch 10: Loss = 0.0832, Accuracy = 87.36%
Training on dataloader 30/38
/home/bce22157/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
my_code.py:543: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()
  Batch 0: Loss = 0.3680, Accuracy = 87.33%
  Batch 5: Loss = 0.0790, Accuracy = 87.36%
  Batch 10: Loss = 1.5918, Accuracy = 87.24%
Error in batch 12 of dataloader 29: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 31/38
  Batch 0: Loss = 0.1070, Accuracy = 87.27%
  Batch 5: Loss = 0.0771, Accuracy = 87.36%
  Batch 10: Loss = 0.0760, Accuracy = 87.51%
  Batch 15: Loss = 0.1008, Accuracy = 87.57%
  Batch 20: Loss = 0.4597, Accuracy = 87.66%
Training on dataloader 32/38
  Batch 0: Loss = 0.2183, Accuracy = 87.71%
  Batch 5: Loss = 0.0708, Accuracy = 87.82%
  Batch 10: Loss = 0.2600, Accuracy = 87.90%
  Batch 15: Loss = 0.0863, Accuracy = 88.04%
  Batch 20: Loss = 0.0591, Accuracy = 88.14%
Training on dataloader 33/38
  Batch 0: Loss = 0.4195, Accuracy = 88.19%
  Batch 5: Loss = 0.0606, Accuracy = 88.31%
  Batch 10: Loss = 1.2297, Accuracy = 88.39%
  Batch 15: Loss = 0.0649, Accuracy = 88.51%
  Batch 20: Loss = 0.0664, Accuracy = 88.63%
Error in batch 22 of dataloader 32: Expected more than 1 value per channel when training, got input size torch.Size([1, 1024])
Training on dataloader 34/38
  Batch 0: Loss = 0.0640, Accuracy = 88.68%
  Batch 5: Loss = 0.0895, Accuracy = 88.69%
  Batch 10: Loss = 0.8281, Accuracy = 88.68%
Training on dataloader 35/38
  Batch 0: Loss = 0.1699, Accuracy = 88.69%
  Batch 5: Loss = 0.2364, Accuracy = 88.68%
  Batch 10: Loss = 0.4130, Accuracy = 88.62%
Training on dataloader 36/38
  Batch 0: Loss = 0.0746, Accuracy = 88.63%
  Batch 5: Loss = 0.0761, Accuracy = 88.72%
  Batch 10: Loss = 0.0533, Accuracy = 88.83%
  Batch 15: Loss = 0.0513, Accuracy = 88.94%
  Batch 20: Loss = 0.0567, Accuracy = 89.04%
Training on dataloader 37/38
  Batch 0: Loss = 0.0663, Accuracy = 89.15%
  Batch 5: Loss = 0.0592, Accuracy = 89.25%
  Batch 10: Loss = 0.0660, Accuracy = 89.35%
  Batch 15: Loss = 0.1203, Accuracy = 89.45%
  Batch 20: Loss = 0.0807, Accuracy = 89.54%
Training on dataloader 38/38
  Batch 0: Loss = 0.4693, Accuracy = 89.55%
  Batch 5: Loss = 0.2758, Accuracy = 89.55%
  Batch 10: Loss = 0.7422, Accuracy = 89.44%

=== TRAINING EPOCH SUMMARY ===
Average Loss: 0.3379
Accuracy: 89.42%
Total Samples: 4488
==============================
Evaluating on dataloader 1/3
  Batch 0: Loss = 0.2337, Accuracy = 87.50%
  Batch 5: Loss = 0.0283, Accuracy = 93.75%
  Batch 10: Loss = 0.3328, Accuracy = 94.32%
  Batch 15: Loss = 0.0455, Accuracy = 96.09%
  Batch 20: Loss = 0.0348, Accuracy = 97.02%
Evaluating on dataloader 2/3
  Batch 0: Loss = 0.1025, Accuracy = 97.35%
  Batch 5: Loss = 0.0314, Accuracy = 97.38%
  Batch 10: Loss = 0.0274, Accuracy = 97.40%
  Batch 15: Loss = 0.0903, Accuracy = 97.73%
  Batch 20: Loss = 0.8520, Accuracy = 96.85%
  Batch 25: Loss = 0.0399, Accuracy = 96.63%
Evaluating on dataloader 3/3
  Batch 0: Loss = 0.0733, Accuracy = 96.70%
  Batch 5: Loss = 0.4513, Accuracy = 95.62%
  Batch 10: Loss = 0.4569, Accuracy = 94.94%

=== VALIDATION EPOCH SUMMARY ===
Average Loss: 0.1637
Accuracy: 94.83%
Total Samples: 484
===================================
No improvement in validation accuracy. Patience: 5/5
Early stopping triggered!

Training completed!
Best validation accuracy: 95.87%
